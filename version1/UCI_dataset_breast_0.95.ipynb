{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "from classifiers import TransparentLogisticRegression\n",
    "from matplotlib import pylab as pl\n",
    "from scipy.sparse import diags\n",
    "from IPython import display\n",
    "from scale import decision_tree_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# breast-w\n",
    "# source link: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29\n",
    "# relevant paper: Multisurface method of pattern separation for medical diagnosis applied to breast cytology\n",
    "\n",
    "dataset = \"breast-w.csv\"\n",
    "class_index = 9\n",
    "num_cols = 10\n",
    "classes = ['benign', 'malignant']\n",
    "read_cols = [i for i in range(num_cols) if i != class_index]\n",
    "file_path = \"D:\\\\IIT_Master\\\\2016 Spring\\\\CS597\\\\uci\\\\uci\\\\uci-tar\\\\nominal\\\\\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clump_Thickness' 'Cell_Size_Uniformity' 'Cell_Shape_Uniformity'\n",
      " 'Marginal_Adhesion' 'Single_Epi_Cell_Size' 'Bare_Nuclei' 'Bland_Chromatin'\n",
      " 'Normal_Nucleoli' 'Mitoses' 'Class\\n']\n"
     ]
    }
   ],
   "source": [
    "# ['Clump_Thickness' 'Cell_Size_Uniformity' 'Cell_Shape_Uniformity' 'Marginal_Adhesion' 'Single_Epi_Cell_Size' 'Bare_Nuclei' 'Bland_Chromatin'\n",
    "#  'Normal_Nucleoli' 'Mitoses' \n",
    "\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline()\n",
    "    #print header\n",
    "    #header = np.fromstring(\"a, b\", dtype=np.str_, sep=',')\n",
    "    header = np.array(header.split(','))\n",
    "    feature_names = header[read_cols]\n",
    "    \n",
    "    print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (699L, 9L)\n",
      "665\n"
     ]
    }
   ],
   "source": [
    "# Loading the data and splitting the train, test\n",
    "\n",
    "X = np.loadtxt(file_path, dtype=float, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=read_cols)\n",
    "y = np.loadtxt(file_path, dtype=int, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=(class_index,), converters={class_index: lambda x: classes.index(x)})\n",
    "\n",
    "num_inst, num_feat = np.shape(X)\n",
    "print \"The shape of X:\",np.shape(X)\n",
    "\n",
    "ss = ShuffleSplit(num_inst, n_iter=1, test_size=0.95, random_state=2)\n",
    "\n",
    "for i, j in ss:\n",
    "    train_index = i \n",
    "    test_index = j\n",
    "    \n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine binary features\n",
    "num_features = X.shape[1]\n",
    "non_binary = []\n",
    "binary = []\n",
    "for i in range(num_features):\n",
    "    if len(np.unique(X[:,i])) != 2:\n",
    "        non_binary.append(i)\n",
    "    else:\n",
    "        binary.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Scale for non_binary features -- Train\n",
      "IG Scale for non_binary features -- Test\n"
     ]
    }
   ],
   "source": [
    "# Original features\n",
    "X_original = np.copy(X)\n",
    "\n",
    "X_train_ori = X_original[train_index]\n",
    "X_test_ori = X_original[test_index]\n",
    "\n",
    "# Standard scale non binary features\n",
    "# X_ss = scale(X)\n",
    "X_ss = np.copy(X)\n",
    "\n",
    "if len(non_binary) > 0:\n",
    "    X_ss[:,non_binary]=scale(X[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_ss[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_ss[:,binary] = X_b\n",
    "    \n",
    "X_train_ss = X_ss[train_index]\n",
    "X_test_ss = X_ss[test_index]\n",
    "\n",
    "# Information gain scaling non binary features\n",
    "\n",
    "X_ig = np.copy(X_original)\n",
    "scale_ = decision_tree_scale()\n",
    "\n",
    "X_train_ig = X_ig[train_index]\n",
    "X_test_ig = X_ig[test_index]\n",
    "\n",
    "if len(non_binary) > 0: \n",
    "    print \"IG Scale for non_binary features -- Train\"\n",
    "    X_train_ig[:,non_binary]=scale_.fit_transform(X_train_ig[:,non_binary], y_train)\n",
    "\n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_train_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_train_ig[:,binary] = X_b\n",
    "    \n",
    "if len(non_binary) > 0:\n",
    "    \n",
    "    print \"IG Scale for non_binary features -- Test\"\n",
    "    X_test_ig[:,non_binary]=scale_.transform(X_test_ig[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0:\n",
    "    \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_test_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_test_ig[:,binary] = X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of each features:\n",
      "[ 4.41773963  3.13447783  3.2074392   2.80686695  3.21602289  3.54465593\n",
      "  3.43776824  2.86695279  1.58941345]\n",
      "The best splitting of each features\n",
      "[ 4.5  2.5  2.5  1.5  3.5  3.   4.5  3.5  1.5]\n"
     ]
    }
   ],
   "source": [
    "print \"The mean of each features:\"\n",
    "print np.mean(X, axis=0)\n",
    "print \"The best splitting of each features\"\n",
    "print scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_ori = TransparentLogisticRegression()\n",
    "clf_ss = TransparentLogisticRegression()\n",
    "clf_ig = TransparentLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransparentLogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "               fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "               multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "               random_state=None, solver='liblinear', tol=0.0001,\n",
       "               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit train instances for each classifier\n",
    "\n",
    "clf_ori.fit(X_train_ori, y_train)\n",
    "clf_ss.fit(X_train_ss, y_train)\n",
    "clf_ig.fit(X_train_ig, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38583135  0.17938236  0.23548352  0.0232745  -0.70374158  1.33136849\n",
      "  -0.50101944  0.43533379 -0.41052578]]\n",
      "[[ 0.63586749  0.60064158  0.66842156  0.62853418  0.19613929  0.92188635\n",
      "   0.47273588  0.72327142  0.16628945]]\n",
      "[[ 0.69309021  0.5936199   0.68854328  0.52035959  0.25596195  0.85901456\n",
      "   0.60150623  0.82816488  0.13214529]]\n",
      "\n",
      "[-1.26210743]\n",
      "[-0.29890278]\n",
      "[-0.35049499]\n"
     ]
    }
   ],
   "source": [
    "# print the weights for each classifiers\n",
    "\n",
    "print clf_ori.coef_\n",
    "print clf_ss.coef_\n",
    "print clf_ig.coef_\n",
    "print \"\"\n",
    "\n",
    "print clf_ori.intercept_ \n",
    "print clf_ss.intercept_ \n",
    "print clf_ig.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867669172932\n",
      "0.96992481203\n",
      "0.971428571429\n"
     ]
    }
   ],
   "source": [
    "# Predict test instances for each classifier\n",
    "\n",
    "y_predict_ori = clf_ori.predict(X_test_ori)\n",
    "y_pred_prob_ori = clf_ori.predict_proba(X_test_ori)\n",
    "neg_evi_ori, pos_evi_ori = clf_ori.predict_evidences(X_test_ori)\n",
    "\n",
    "y_predict_ss = clf_ss.predict(X_test_ss)\n",
    "y_pred_prob_ss = clf_ss.predict_proba(X_test_ss)\n",
    "neg_evi_ss, pos_evi_ss = clf_ss.predict_evidences(X_test_ss)\n",
    "\n",
    "y_predict_ig = clf_ig.predict(X_test_ig)\n",
    "y_pred_prob_ig = clf_ig.predict_proba(X_test_ig)\n",
    "neg_evi_ig, pos_evi_ig = clf_ig.predict_evidences(X_test_ig)\n",
    "\n",
    "print accuracy_score(y_test,y_predict_ori)\n",
    "print accuracy_score(y_test,y_predict_ss)\n",
    "print accuracy_score(y_test,y_predict_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(benign) instances based on probability\n",
      "Index of test:  495\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.  10.   1.   8.   8.   8.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  3.06590584 -0.70699139\n",
      "  1.87236122  1.68216723  3.74045801]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  2.79032397 -0.49324598\n",
      "  1.35009522  1.53422494  3.04921869]\n",
      "\n",
      "Standard scaling: Most negative(benign) instances based on probability\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -1.07320153 -0.49324598\n",
      " -1.35009522 -0.85234719 -0.23455528]\n",
      "\n",
      "Information gain scaling: Most negative(benign) instances based on probability\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -1.07320153 -0.49324598\n",
      " -1.35009522 -0.85234719 -0.23455528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"benign\" -- Probability\n",
    "\n",
    "Most_negative_1 = np.argmax(y_pred_prob_ori[:,0])\n",
    "print \"Original: Most negative(benign) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_1]\n",
    "print X_test_ss[Most_negative_1]\n",
    "print X_test_ig[Most_negative_1]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_2 = np.argmax(y_pred_prob_ss[:,0])\n",
    "print \"Standard scaling: Most negative(benign) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_2]\n",
    "print X_test_ss[Most_negative_2]\n",
    "print X_test_ig[Most_negative_2]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_3 = np.argmax(y_pred_prob_ig[:,0])\n",
    "print \"Information gain scaling: Most negative(benign) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_3]\n",
    "print X_test_ss[Most_negative_3]\n",
    "print X_test_ig[Most_negative_3]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(malignant) instances based on probability\n",
      "Index of test:  62\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  6.  10.  10.  10.   4.  10.   7.  10.   1.]\n",
      "[ 0.56233637  2.25152563  2.28722218  2.52095546  0.35430544  1.79351268\n",
      "  1.46195655  2.33759359 -0.34391178]\n",
      "[ 0.53984125  2.5227748   2.65899235  2.42276144  0.21464031  1.72636091\n",
      "  0.96435373  2.21610269 -0.23455528]\n",
      "\n",
      "Standard scaling: Most positive(malignant) instances based on probability\n",
      "Index of test:  554\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   5.  10.  10.  10.   7.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  0.80623884  1.79351268\n",
      "  2.69317056  2.33759359  3.15697661]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  0.64392092  1.72636091\n",
      "  2.12157821  2.21610269  2.58010812]\n",
      "\n",
      "Information gain scaling: Most positive(malignant) instances based on probability\n",
      "Index of test:  554\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   5.  10.  10.  10.   7.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  0.80623884  1.79351268\n",
      "  2.69317056  2.33759359  3.15697661]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  0.64392092  1.72636091\n",
      "  2.12157821  2.21610269  2.58010812]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"malignant\" -- Probability\n",
    "\n",
    "Most_positive_1 = np.argmax(y_pred_prob_ori[:,1])\n",
    "\n",
    "\n",
    "print \"Original: Most positive(malignant) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_1]\n",
    "print X_test_ss[Most_positive_1]\n",
    "print X_test_ig[Most_positive_1]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_2 = np.argmax(y_pred_prob_ss[:,1])\n",
    "print \"Standard scaling: Most positive(malignant) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_2]\n",
    "print X_test_ss[Most_positive_2]\n",
    "print X_test_ig[Most_positive_2]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_3 = np.argmax(y_pred_prob_ig[:,1])\n",
    "print \"Information gain scaling: Most positive(malignant) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_3]\n",
    "print X_test_ss[Most_positive_3]\n",
    "print X_test_ig[Most_positive_3]\n",
    "print \"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(benign) instances based on evidence\n",
      "Index of test:  579\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  9.  10.  10.  10.  10.   5.  10.  10.  10.]\n",
      "[ 1.62853834  2.25152563  2.28722218  2.52095546  3.06590584  0.40434375\n",
      "  2.69317056  2.33759359  4.9074208 ]\n",
      "[ 1.61952374  2.5227748   2.65899235  2.42276144  2.79032397  0.49324598\n",
      "  2.12157821  2.21610269  3.98743983]\n",
      "\n",
      "Standard scaling: Most negative(benign) instances based on evidence\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -1.07320153 -0.49324598\n",
      " -1.35009522 -0.85234719 -0.23455528]\n",
      "\n",
      "Information gain scaling: Most negative(benign) instances based on evidence\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -1.07320153 -0.49324598\n",
      " -1.35009522 -0.85234719 -0.23455528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"benign\" -- Evidence\n",
    "\n",
    "negative_evi_index_ori = np.argmax(abs(neg_evi_ori))\n",
    "print \"Original: Most negative(benign) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ori]\n",
    "print X_test_ss[negative_evi_index_ori]\n",
    "print X_test_ig[negative_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ss = np.argmax(abs(neg_evi_ss))\n",
    "print \"Standard scaling: Most negative(benign) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ss]\n",
    "print X_test_ss[negative_evi_index_ss]\n",
    "print X_test_ig[negative_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ig = np.argmax(abs(neg_evi_ig))\n",
    "print \"Information gain scaling: Most negative(benign) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ig]\n",
    "print X_test_ss[negative_evi_index_ig]\n",
    "print X_test_ig[negative_evi_index_ig]\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(malignant) instances based on evidence\n",
      "Index of test:  62\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  6.  10.  10.  10.   4.  10.   7.  10.   1.]\n",
      "[ 0.56233637  2.25152563  2.28722218  2.52095546  0.35430544  1.79351268\n",
      "  1.46195655  2.33759359 -0.34391178]\n",
      "[ 0.53984125  2.5227748   2.65899235  2.42276144  0.21464031  1.72636091\n",
      "  0.96435373  2.21610269 -0.23455528]\n",
      "\n",
      "Standard scaling: Most positive(malignant) instances based on evidence\n",
      "Index of test:  554\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   5.  10.  10.  10.   7.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  0.80623884  1.79351268\n",
      "  2.69317056  2.33759359  3.15697661]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  0.64392092  1.72636091\n",
      "  2.12157821  2.21610269  2.58010812]\n",
      "\n",
      "Information gain scaling: Most positive(malignant) instances based on evidence\n",
      "Index of test:  554\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   5.  10.  10.  10.   7.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  0.80623884  1.79351268\n",
      "  2.69317056  2.33759359  3.15697661]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  0.64392092  1.72636091\n",
      "  2.12157821  2.21610269  2.58010812]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"mallignant\" -- Evidence \n",
    "\n",
    "positive_evi_index_ori = np.argmax(pos_evi_ori)\n",
    "print \"Original: Most positive(malignant) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ori]\n",
    "print X_test_ss[positive_evi_index_ori]\n",
    "print X_test_ig[positive_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ss = np.argmax(pos_evi_ss)\n",
    "print \"Standard scaling: Most positive(malignant) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ss]\n",
    "print X_test_ss[positive_evi_index_ss]\n",
    "print X_test_ig[positive_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ig = np.argmax(pos_evi_ig)\n",
    "print \"Information gain scaling: Most positive(malignant) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ig]\n",
    "print X_test_ss[positive_evi_index_ig]\n",
    "print X_test_ig[positive_evi_index_ig]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most uncertain instance based on probability\n",
      "Index of test:  207\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 7.  2.  4.  1.  3.  4.  3.  3.  1.]\n",
      "[ 0.91773703 -0.37204831  0.2668747  -0.63324716 -0.09762796  0.12650997\n",
      " -0.17966213  0.04360132 -0.34391178]\n",
      "[ 0.89973541 -0.16818499  0.53179847 -0.14251538 -0.21464031  0.24662299\n",
      " -0.57861224 -0.17046944 -0.23455528]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  159\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 2.  3.  4.  4.  2.  5.  2.  5.  1.]\n",
      "[-0.85926625 -0.04410156  0.2668747   0.41815371 -0.54956136  0.40434375\n",
      " -0.5900668   0.69902769 -0.34391178]\n",
      "[-0.89973541  0.16818499  0.53179847  0.71257689 -0.64392092  0.49324598\n",
      " -0.96435373  0.51140831 -0.23455528]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  154\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 5.  3.  3.  3.  2.  3.  4.  4.  1.]\n",
      "[ 0.20693572 -0.04410156 -0.06984988  0.06768675 -0.54956136 -0.15132382\n",
      "  0.23074254  0.37131451 -0.34391178]\n",
      "[ 0.17994708  0.16818499  0.17726616  0.42754614 -0.64392092  0.\n",
      " -0.19287075  0.17046944 -0.23455528]\n",
      "\n",
      "The splitting point:  [ 4.5  2.5  2.5  1.5  3.5  3.   4.5  3.5  1.5]\n"
     ]
    }
   ],
   "source": [
    "# unc_1 Top 1 uncertain instances\n",
    "\n",
    "uncertains_ori = np.min(y_pred_prob_ori, axis=1)\n",
    "uis_ori = np.argsort(uncertains_ori)[::-1]\n",
    "top10_uis_ori = uis_ori[:10]\n",
    "print \"Original: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ori[0]\n",
    "print \"Actual label\", y_test[uis_ori[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ori[0]]\n",
    "print X_test_ss[uis_ori[0]]\n",
    "print X_test_ig[uis_ori[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ss = np.min(y_pred_prob_ss, axis=1)\n",
    "uis_ss = np.argsort(uncertains_ss)[::-1]\n",
    "top10_uis_ss = uis_ss[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ss[0]\n",
    "print \"Actual label\", y_test[uis_ss[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ss[0]]\n",
    "print X_test_ss[uis_ss[0]]\n",
    "print X_test_ig[uis_ss[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ig = np.min(y_pred_prob_ig, axis=1)\n",
    "uis_ig = np.argsort(uncertains_ig)[::-1]\n",
    "top10_uis_ig = uis_ig[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ig[0]\n",
    "print \"Actual label\", y_test[uis_ig[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ig[0]]\n",
    "print X_test_ss[uis_ig[0]]\n",
    "print X_test_ig[uis_ig[0]]\n",
    "print \"\"\n",
    "\n",
    "print \"The splitting point: \", scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207 154 131 504 384 158  88 145 523 333]\n",
      "[159 559 154 227 207 605   0 461 256 178]\n",
      "[154 159 559 207 116 178 605 637   0 575]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 uncertain instances for each classifier\n",
    "\n",
    "print top10_uis_ori\n",
    "print top10_uis_ss\n",
    "print top10_uis_ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  384\n",
      "Actual label 1\n",
      "[  8.   7.   4.   4.   5.   3.   5.  10.   1.]\n",
      "[ 1.27313768  1.26768541  0.2668747   0.41815371  0.80623884 -0.15132382\n",
      "  0.64114721  2.33759359 -0.34391178]\n",
      "[ 1.25962958  1.51366488  0.53179847  0.71257689  0.64392092  0.\n",
      "  0.19287075  2.21610269 -0.23455528]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  605\n",
      "Actual label 0\n",
      "[ 3.  1.  1.  3.  8.  1.  5.  8.  1.]\n",
      "[-0.50386559 -0.69999505 -0.74329904  0.06768675  2.16203904 -0.70699139\n",
      "  0.64114721  1.68216723 -0.34391178]\n",
      "[-0.53984125 -0.50455496 -0.53179847  0.42754614  1.93176275 -0.49324598\n",
      "  0.19287075  1.53422494 -0.23455528]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  0\n",
      "Actual label 1\n",
      "[ 10.   2.   2.   1.   2.   6.   1.   1.   2.]\n",
      "[ 1.983939   -0.37204831 -0.40657446 -0.63324716 -0.54956136  0.68217754\n",
      " -1.00047147 -0.61182504  0.23956962]\n",
      "[ 1.9794179  -0.16818499 -0.17726616 -0.14251538 -0.64392092  0.73986896\n",
      " -1.35009522 -0.85234719  0.23455528]\n"
     ]
    }
   ],
   "source": [
    "# unc_ce from Top 10 uncertain instances\n",
    "\n",
    "min_evidence_top10_ori = np.min([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ce_ori = np.argmax(min_evidence_top10_ori)\n",
    "print \"Original: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ce_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ce_ori]]\n",
    "\n",
    "min_evidence_top10_ss = np.min([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ce_ss = np.argmax(min_evidence_top10_ss)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ce_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ce_ss]]\n",
    "\n",
    "min_evidence_top10_ig = np.min([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ce_ig = np.argmax(min_evidence_top10_ig)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ce_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ce_ig]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  145\n",
      "Actual label 0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  3.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147  0.04360132 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -1.07320153 -0.49324598\n",
      " -1.35009522 -0.17046944 -0.23455528]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  154\n",
      "Actual label 1\n",
      "[ 5.  3.  3.  3.  2.  3.  4.  4.  1.]\n",
      "[ 0.20693572 -0.04410156 -0.06984988  0.06768675 -0.54956136 -0.15132382\n",
      "  0.23074254  0.37131451 -0.34391178]\n",
      "[ 0.17994708  0.16818499  0.17726616  0.42754614 -0.64392092  0.\n",
      " -0.19287075  0.17046944 -0.23455528]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  154\n",
      "Actual label 1\n",
      "[ 5.  3.  3.  3.  2.  3.  4.  4.  1.]\n",
      "[ 0.20693572 -0.04410156 -0.06984988  0.06768675 -0.54956136 -0.15132382\n",
      "  0.23074254  0.37131451 -0.34391178]\n",
      "[ 0.17994708  0.16818499  0.17726616  0.42754614 -0.64392092  0.\n",
      " -0.19287075  0.17046944 -0.23455528]\n"
     ]
    }
   ],
   "source": [
    "# unc_ie from Top 10 uncertain instances \n",
    "\n",
    "max_evidence_top10_ori = np.max([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ie_ori = np.argmin(max_evidence_top10_ori)\n",
    "print \"Original: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ie_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ie_ori]]\n",
    "\n",
    "max_evidence_top10_ss = np.max([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ie_ss = np.argmin(max_evidence_top10_ss)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ie_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ie_ss]]\n",
    "\n",
    "max_evidence_top10_ig = np.max([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ie_ig = np.argmin(max_evidence_top10_ig)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ie_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ie_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 356\n",
      "Actual label 1\n",
      "[ 10.  10.  10.  10.  10.  10.   4.  10.  10.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  3.06590584  1.79351268\n",
      "  0.23074254  2.33759359  4.9074208 ]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  2.79032397  1.72636091\n",
      " -0.19287075  2.21610269  3.98743983]\n",
      "\n",
      "Index of test: 450\n",
      "Actual label 1\n",
      "[  9.  10.  10.  10.  10.  10.  10.  10.   1.]\n",
      "[ 1.62853834  2.25152563  2.28722218  2.52095546  3.06590584  1.79351268\n",
      "  2.69317056  2.33759359 -0.34391178]\n",
      "[ 1.61952374  2.5227748   2.65899235  2.42276144  2.79032397  1.72636091\n",
      "  2.12157821  2.21610269 -0.23455528]\n",
      "\n",
      "Index of test: 356\n",
      "Actual label 1\n",
      "[ 10.  10.  10.  10.  10.  10.   4.  10.  10.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  3.06590584  1.79351268\n",
      "  0.23074254  2.33759359  4.9074208 ]\n",
      "[ 1.9794179   2.5227748   2.65899235  2.42276144  2.79032397  1.72636091\n",
      " -0.19287075  2.21610269  3.98743983]\n"
     ]
    }
   ],
   "source": [
    "# Least negative among Top 10 possitive \n",
    "\n",
    "top_positive_index_ori = np.argsort(pos_evi_ori)[::-1]\n",
    "tp_ori = top_positive_index_ori[:10]\n",
    "neg_info_ori = neg_evi_ori[tp_ori]\n",
    "index_least_neg_ori = np.argmin(neg_info_ori)\n",
    "print \"Index of test:\",tp_ori[index_least_neg_ori]\n",
    "print \"Actual label\", y_test[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ori[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ss[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ig[tp_ori[index_least_neg_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ss = np.argsort(pos_evi_ss)[::-1]\n",
    "tp_ss = top_positive_index_ss[:10]\n",
    "neg_info_ss = neg_evi_ss[tp_ss]\n",
    "index_least_neg_ss = np.argmin(neg_info_ss)\n",
    "print \"Index of test:\",tp_ss[index_least_neg_ss]\n",
    "print \"Actual label\", y_test[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ori[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ss[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ig[tp_ss[index_least_neg_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ig = np.argsort(pos_evi_ig)[::-1]\n",
    "tp_ig = top_positive_index_ig[:10]\n",
    "neg_info_ig = neg_evi_ig[tp_ig]\n",
    "index_least_neg_ig = np.argmin(neg_info_ig)\n",
    "print \"Index of test:\",tp_ig[index_least_neg_ig]\n",
    "print \"Actual label\", y_test[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ori[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ss[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ig[tp_ig[index_least_neg_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450 642  62 356 102 554 248 474 166 269]\n",
      "[554 248 450 356 269 102 579 166 474 642]\n",
      "[554 450 248 356 579 102 269 166 474 422]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 positive based on positive evidence\n",
    "\n",
    "print tp_ori\n",
    "print tp_ss\n",
    "print tp_ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 579\n",
      "Actual label 1\n",
      "[  9.  10.  10.  10.  10.   5.  10.  10.  10.]\n",
      "[ 1.62853834  2.25152563  2.28722218  2.52095546  3.06590584  0.40434375\n",
      "  2.69317056  2.33759359  4.9074208 ]\n",
      "[ 1.61952374  2.5227748   2.65899235  2.42276144  2.79032397  0.49324598\n",
      "  2.12157821  2.21610269  3.98743983]\n",
      "\n",
      "Index of test: 413\n",
      "Actual label 0\n",
      "[ 1.  1.  1.  1.  2.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -0.54956136 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -0.64392092 -0.49324598\n",
      " -1.35009522 -0.85234719 -0.23455528]\n",
      "\n",
      "Index of test: 120\n",
      "Actual label 0\n",
      "[ 1.  1.  1.  1.  2.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -0.54956136 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.25962958 -0.50455496 -0.53179847 -0.14251538 -0.64392092 -0.49324598\n",
      " -1.35009522 -0.85234719 -0.23455528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Least positive among Top 10 negative instances\n",
    "\n",
    "top_negative_index_ori = np.argsort(abs(neg_evi_ori))[::-1]\n",
    "tn_ori = top_negative_index_ori[:10]\n",
    "pos_info_ori = pos_evi_ori[tp_ori]\n",
    "index_least_pos_ori = np.argmin(pos_info_ori)\n",
    "print \"Index of test:\",tn_ori[index_least_pos_ori]\n",
    "print \"Actual label\", y_test[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ori[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ss[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ig[tn_ori[index_least_pos_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ss = np.argsort(abs(neg_evi_ss))[::-1]\n",
    "tn_ss = top_negative_index_ss[:10]\n",
    "pos_info_ss = pos_evi_ss[tp_ss]\n",
    "index_least_pos_ss = np.argmin(pos_info_ss)\n",
    "print \"Index of test:\",tn_ss[index_least_pos_ss]\n",
    "print \"Actual label\", y_test[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ori[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ss[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ig[tn_ss[index_least_pos_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ig = np.argsort(abs(neg_evi_ig))[::-1]\n",
    "tn_ig = top_negative_index_ig[:10]\n",
    "pos_info_ig = pos_evi_ig[tp_ig]\n",
    "index_least_pos_ig = np.argmin(pos_info_ig)\n",
    "print \"Index of test:\",tn_ig[index_least_pos_ig]\n",
    "print \"Actual label\", y_test[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ori[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ss[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ig[tn_ig[index_least_pos_ig]]\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[579 495 652 356 308 532 550 248 534 450]\n",
      "[288 127 180  32 285 643 277 640 540 413]\n",
      "[ 32 288 180 127 372 349  95 640 432 120]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 negative based on negative evidence\n",
    "\n",
    "print tn_ori\n",
    "print tn_ss\n",
    "print tn_ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
