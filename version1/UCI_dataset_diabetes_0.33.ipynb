{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "from classifiers import TransparentLogisticRegression\n",
    "from matplotlib import pylab as pl\n",
    "from scipy.sparse import diags\n",
    "from IPython import display\n",
    "from scale import decision_tree_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diabetes  http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes\n",
    "# ['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age']\n",
    "# preg: the # of pregnant \n",
    "# plas: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "# pres: Diastolic blood pressure\n",
    "# skin: Triceps skin fold thickness\n",
    "# insu: 2-Hour serum insulin\n",
    "# mass: Body mass index\n",
    "# pedi: Diabetes pedigree function \n",
    "# Age \n",
    "\n",
    "dataset = \"diabetes.csv\"\n",
    "class_index = 8\n",
    "num_cols = 9\n",
    "classes= ['tested_negative', 'tested_positive']\n",
    "read_cols = [i for i in range(num_cols) if i != class_index]\n",
    "file_path = \"D:\\\\IIT_Master\\\\2016 Spring\\\\CS597\\\\uci\\\\uci\\\\uci-tar\\\\nominal\\\\\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age' 'class\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline()\n",
    "    #print header\n",
    "    #header = np.fromstring(\"a, b\", dtype=np.str_, sep=',')\n",
    "    header = np.array(header.split(','))\n",
    "    feature_names = header[read_cols]\n",
    "    \n",
    "    print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (768L, 8L)\n",
      "254\n"
     ]
    }
   ],
   "source": [
    "# Loading the data and splitting the train, test\n",
    "\n",
    "X = np.loadtxt(file_path, dtype=float, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=read_cols)\n",
    "y = np.loadtxt(file_path, dtype=int, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=(class_index,), converters={class_index: lambda x: classes.index(x)})\n",
    "\n",
    "num_inst, num_feat = np.shape(X)\n",
    "print \"The shape of X:\",np.shape(X)\n",
    "ss = ShuffleSplit(num_inst, n_iter=1, test_size=0.33, random_state=40)\n",
    "\n",
    "for i, j in ss:\n",
    "    train_index = i \n",
    "    test_index = j\n",
    "    \n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine binary features\n",
    "num_features = X.shape[1]\n",
    "non_binary = []\n",
    "binary = []\n",
    "for i in range(num_features):\n",
    "    if len(np.unique(X[:,i])) != 2:\n",
    "        non_binary.append(i)\n",
    "    else:\n",
    "        binary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Scale for non_binary features -- Train\n",
      "IG Scale for non_binary features -- Test\n",
      "['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age']\n"
     ]
    }
   ],
   "source": [
    "# Original features\n",
    "X_original = np.copy(X)\n",
    "\n",
    "X_train_ori = X_original[train_index]\n",
    "X_test_ori = X_original[test_index]\n",
    "\n",
    "# Standard scale non binary features\n",
    "\n",
    "X_ss = np.copy(X)\n",
    "# X_ss = scale(X)\n",
    "\n",
    "if len(non_binary) > 0:\n",
    "    X_ss[:,non_binary]=scale(X[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_ss[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_ss[:,binary] = X_b\n",
    "    \n",
    "X_train_ss = X_ss[train_index]\n",
    "X_test_ss = X_ss[test_index]\n",
    "\n",
    "# Information gain scaling non binary features\n",
    "\n",
    "X_ig = np.copy(X_original)\n",
    "scale_ = decision_tree_scale()\n",
    "\n",
    "X_train_ig = X_ig[train_index]\n",
    "X_test_ig = X_ig[test_index]\n",
    "\n",
    "if len(non_binary) > 0: \n",
    "    print \"IG Scale for non_binary features -- Train\"\n",
    "    X_train_ig[:,non_binary]=scale_.fit_transform(X_train_ig[:,non_binary], y_train)\n",
    "\n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_train_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_train_ig[:,binary] = X_b\n",
    "    \n",
    "if len(non_binary) > 0:\n",
    "    \n",
    "    print \"IG Scale for non_binary features -- Test\"\n",
    "    X_test_ig[:,non_binary]=scale_.transform(X_test_ig[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0:\n",
    "    \n",
    "    print \"binary features exist\"\n",
    "    print binary\n",
    "    X_b = X_test_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_test_ig[:,binary] = X_b\n",
    "\n",
    "print header[non_binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of each features:\n",
      "[   3.84505208  120.89453125   69.10546875   20.53645833   79.79947917\n",
      "   31.99257812    0.4718763    33.24088542]\n",
      "The best splitting of each features\n",
      "[   6.5     127.5      69.       28.5     122.5      26.9       0.2375\n",
      "   28.5   ]\n"
     ]
    }
   ],
   "source": [
    "print \"The mean of each features:\"\n",
    "print np.mean(X, axis=0)\n",
    "print \"The best splitting of each features\"\n",
    "print scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_ori = TransparentLogisticRegression()\n",
    "clf_ss = TransparentLogisticRegression()\n",
    "clf_ig = TransparentLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransparentLogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "               fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "               multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "               random_state=None, solver='liblinear', tol=0.0001,\n",
       "               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit train instances for each classifier\n",
    "\n",
    "clf_ori.fit(X_train_ori, y_train)\n",
    "clf_ss.fit(X_train_ss, y_train)\n",
    "clf_ig.fit(X_train_ig, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1439551   0.02524085 -0.01827704  0.00804746 -0.00147434  0.0478546\n",
      "   0.70378772  0.00439795]]\n",
      "[[ 0.52972941  1.05425945 -0.28093931  0.13508668 -0.24497126  0.62607176\n",
      "   0.32810724  0.15760426]]\n",
      "[[ 0.68734354  1.04734965 -0.29487411  0.16932919 -0.25526673  0.73524881\n",
      "   0.38840003  0.15454245]]\n",
      "\n",
      "[-5.21357724]\n",
      "[-0.95714373]\n",
      "[-1.00087082]\n"
     ]
    }
   ],
   "source": [
    "# print the weights for each classifiers\n",
    "\n",
    "print clf_ori.coef_\n",
    "print clf_ss.coef_\n",
    "print clf_ig.coef_\n",
    "print \"\"\n",
    "\n",
    "print clf_ori.intercept_ \n",
    "print clf_ss.intercept_ \n",
    "print clf_ig.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732283464567\n",
      "0.732283464567\n",
      "0.740157480315\n"
     ]
    }
   ],
   "source": [
    "# Predict test instances for each classifier\n",
    "\n",
    "y_predict_ori = clf_ori.predict(X_test_ori)\n",
    "y_pred_prob_ori = clf_ori.predict_proba(X_test_ori)\n",
    "neg_evi_ori, pos_evi_ori = clf_ori.predict_evidences(X_test_ori)\n",
    "\n",
    "y_predict_ss = clf_ss.predict(X_test_ss)\n",
    "y_pred_prob_ss = clf_ss.predict_proba(X_test_ss)\n",
    "neg_evi_ss, pos_evi_ss = clf_ss.predict_evidences(X_test_ss)\n",
    "\n",
    "y_predict_ig = clf_ig.predict(X_test_ig)\n",
    "y_pred_prob_ig = clf_ig.predict_proba(X_test_ig)\n",
    "neg_evi_ig, pos_evi_ig = clf_ig.predict_evidences(X_test_ig)\n",
    "\n",
    "print accuracy_score(y_test,y_predict_ori)\n",
    "print accuracy_score(y_test,y_predict_ss)\n",
    "print accuracy_score(y_test,y_predict_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(tested_negative) instances based on probability\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.28010463 -4.04081109 -1.02504413 -0.45963455 -1.0108045  -0.23020211\n",
      " -0.24019749 -0.52546546]\n",
      "\n",
      "Standard scaling: Most negative(tested_negative) instances based on probability\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.28010463 -4.04081109 -1.02504413 -0.45963455 -1.0108045  -0.23020211\n",
      " -0.24019749 -0.52546546]\n",
      "\n",
      "Information gain scaling: Most negative(tested_negative) instances based on probability\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.28010463 -4.04081109 -1.02504413 -0.45963455 -1.0108045  -0.23020211\n",
      " -0.24019749 -0.52546546]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"tested_negative\" -- Probability\n",
    "\n",
    "Most_negative_1 = np.argmax(y_pred_prob_ori[:,0])\n",
    "print \"Original: Most negative(tested_negative) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_1]\n",
    "print X_test_ss[Most_negative_1]\n",
    "print X_test_ig[Most_negative_1]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_2 = np.argmax(y_pred_prob_ss[:,0])\n",
    "print \"Standard scaling: Most negative(tested_negative) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_2]\n",
    "print X_test_ss[Most_negative_2]\n",
    "print X_test_ig[Most_negative_2]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_3 = np.argmax(y_pred_prob_ig[:,0])\n",
    "print \"Information gain scaling: Most negative(tested_negative) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_3]\n",
    "print X_test_ss[Most_negative_3]\n",
    "print X_test_ig[Most_negative_3]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(tested_positive) instances based on probability\n",
      "Index of test:  199\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  17.     163.      72.      41.     114.      40.9      0.817   47.   ]\n",
      "[ 3.90657835  1.31778097  0.14964075  1.28363829  0.29695956  1.13052326\n",
      "  1.04231453  1.17073215]\n",
      "[ 2.44383611  1.12508858  0.14643488  0.67593316 -0.07013746  1.46492249\n",
      "  1.42763533  1.49555553]\n",
      "\n",
      "Standard scaling: Most positive(tested_positive) instances based on probability\n",
      "Index of test:  199\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  17.     163.      72.      41.     114.      40.9      0.817   47.   ]\n",
      "[ 3.90657835  1.31778097  0.14964075  1.28363829  0.29695956  1.13052326\n",
      "  1.04231453  1.17073215]\n",
      "[ 2.44383611  1.12508858  0.14643488  0.67593316 -0.07013746  1.46492249\n",
      "  1.42763533  1.49555553]\n",
      "\n",
      "Information gain scaling: Most positive(tested_positive) instances based on probability\n",
      "Index of test:  199\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  17.     163.      72.      41.     114.      40.9      0.817   47.   ]\n",
      "[ 3.90657835  1.31778097  0.14964075  1.28363829  0.29695956  1.13052326\n",
      "  1.04231453  1.17073215]\n",
      "[ 2.44383611  1.12508858  0.14643488  0.67593316 -0.07013746  1.46492249\n",
      "  1.42763533  1.49555553]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"tested_positive\" -- Probability\n",
    "\n",
    "Most_positive_1 = np.argmax(y_pred_prob_ori[:,1])\n",
    "\n",
    "\n",
    "print \"Original: Most positive(tested_positive) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_1]\n",
    "print X_test_ss[Most_positive_1]\n",
    "print X_test_ig[Most_positive_1]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_2 = np.argmax(y_pred_prob_ss[:,1])\n",
    "print \"Standard scaling: Most positive(tested_positive) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_2]\n",
    "print X_test_ss[Most_positive_2]\n",
    "print X_test_ig[Most_positive_2]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_3 = np.argmax(y_pred_prob_ig[:,1])\n",
    "print \"Information gain scaling: Most positive(tested_positive) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_3]\n",
    "print X_test_ss[Most_positive_3]\n",
    "print X_test_ig[Most_positive_3]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(tested_negative) instances based on evidence\n",
      "Index of test:  145\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   9.     171.     110.      24.     240.      45.4      0.721   54.   ]\n",
      "[ 1.53084665  1.56815814  2.11415525  0.21726125  1.39100445  1.70165987\n",
      "  0.75238313  1.76634642]\n",
      "[ 0.58186574  1.37862966  2.00127663 -0.24333594  0.96954718  1.93579043\n",
      "  1.19113318  2.06144141]\n",
      "\n",
      "Standard scaling: Most negative(tested_negative) instances based on evidence\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.28010463 -4.04081109 -1.02504413 -0.45963455 -1.0108045  -0.23020211\n",
      " -0.24019749 -0.52546546]\n",
      "\n",
      "Information gain scaling: Most negative(tested_negative) instances based on evidence\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.28010463 -4.04081109 -1.02504413 -0.45963455 -1.0108045  -0.23020211\n",
      " -0.24019749 -0.52546546]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"tested_negative\" -- Evidence\n",
    "\n",
    "negative_evi_index_ori = np.argmax(abs(neg_evi_ori))\n",
    "print \"Original: Most negative(tested_negative) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ori]\n",
    "print X_test_ss[negative_evi_index_ori]\n",
    "print X_test_ig[negative_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ss = np.argmax(abs(neg_evi_ss))\n",
    "print \"Standard scaling: Most negative(tested_negative) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ss]\n",
    "print X_test_ss[negative_evi_index_ss]\n",
    "print X_test_ig[negative_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ig = np.argmax(abs(neg_evi_ig))\n",
    "print \"Information gain scaling: Most negative(tested_negative) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ig]\n",
    "print X_test_ss[negative_evi_index_ig]\n",
    "print X_test_ig[negative_evi_index_ig]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(tested_positive) instances based on evidence\n",
      "Index of test:  199\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  17.     163.      72.      41.     114.      40.9      0.817   47.   ]\n",
      "[ 3.90657835  1.31778097  0.14964075  1.28363829  0.29695956  1.13052326\n",
      "  1.04231453  1.17073215]\n",
      "[ 2.44383611  1.12508858  0.14643488  0.67593316 -0.07013746  1.46492249\n",
      "  1.42763533  1.49555553]\n",
      "\n",
      "Standard scaling: Most positive(tested_positive) instances based on evidence\n",
      "Index of test:  199\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  17.     163.      72.      41.     114.      40.9      0.817   47.   ]\n",
      "[ 3.90657835  1.31778097  0.14964075  1.28363829  0.29695956  1.13052326\n",
      "  1.04231453  1.17073215]\n",
      "[ 2.44383611  1.12508858  0.14643488  0.67593316 -0.07013746  1.46492249\n",
      "  1.42763533  1.49555553]\n",
      "\n",
      "Information gain scaling: Most positive(tested_positive) instances based on evidence\n",
      "Index of test:  199\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  17.     163.      72.      41.     114.      40.9      0.817   47.   ]\n",
      "[ 3.90657835  1.31778097  0.14964075  1.28363829  0.29695956  1.13052326\n",
      "  1.04231453  1.17073215]\n",
      "[ 2.44383611  1.12508858  0.14643488  0.67593316 -0.07013746  1.46492249\n",
      "  1.42763533  1.49555553]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"tested_positive\" -- Evidence \n",
    "\n",
    "positive_evi_index_ori = np.argmax(pos_evi_ori)\n",
    "print \"Original: Most positive(tested_positive) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ori]\n",
    "print X_test_ss[positive_evi_index_ori]\n",
    "print X_test_ig[positive_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ss = np.argmax(pos_evi_ss)\n",
    "print \"Standard scaling: Most positive(tested_positive) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ss]\n",
    "print X_test_ss[positive_evi_index_ss]\n",
    "print X_test_ig[positive_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ig = np.argmax(pos_evi_ig)\n",
    "print \"Information gain scaling: Most positive(tested_positive) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ig]\n",
    "print X_test_ss[positive_evi_index_ig]\n",
    "print X_test_ig[positive_evi_index_ig]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most uncertain instance based on probability\n",
      "Index of test:  45\n",
      "Actual label 0\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  12.     121.      78.      17.       0.      26.5      0.259   62.   ]\n",
      "[ 2.42174604  0.00330087  0.45982725 -0.22183517 -0.69289057 -0.69711387\n",
      " -0.6429117   2.44704844]\n",
      "[ 1.28010463 -0.20600213  0.43930463 -0.62185851 -1.0108045  -0.04185493\n",
      "  0.05296663  2.70816813]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  111\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  0.00000000e+00   1.81000000e+02   8.80000000e+01   4.40000000e+01\n",
      "   5.10000000e+02   4.33000000e+01   2.22000000e-01   2.60000000e+01]\n",
      "[-1.14185152  1.88112959  0.97680475  1.47182248  3.73538635  1.43512945\n",
      " -0.75465609 -0.61611067]\n",
      "[-1.51285093  1.69555602  0.92742088  0.83815712  3.19744282  1.71605206\n",
      " -0.03818524 -0.2021021 ]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  111\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  0.00000000e+00   1.81000000e+02   8.80000000e+01   4.40000000e+01\n",
      "   5.10000000e+02   4.33000000e+01   2.22000000e-01   2.60000000e+01]\n",
      "[-1.14185152  1.88112959  0.97680475  1.47182248  3.73538635  1.43512945\n",
      " -0.75465609 -0.61611067]\n",
      "[-1.51285093  1.69555602  0.92742088  0.83815712  3.19744282  1.71605206\n",
      " -0.03818524 -0.2021021 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unc_1 Top 1 uncertain instances\n",
    "\n",
    "uncertains_ori = np.min(y_pred_prob_ori, axis=1)\n",
    "uis_ori = np.argsort(uncertains_ori)[::-1]\n",
    "top10_uis_ori = uis_ori[:10]\n",
    "print \"Original: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ori[0]\n",
    "print \"Actual label\", y_test[uis_ori[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ori[0]]\n",
    "print X_test_ss[uis_ori[0]]\n",
    "print X_test_ig[uis_ori[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ss = np.min(y_pred_prob_ss, axis=1)\n",
    "uis_ss = np.argsort(uncertains_ss)[::-1]\n",
    "top10_uis_ss = uis_ss[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ss[0]\n",
    "print \"Actual label\", y_test[uis_ss[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ss[0]]\n",
    "print X_test_ss[uis_ss[0]]\n",
    "print X_test_ig[uis_ss[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ig = np.min(y_pred_prob_ig, axis=1)\n",
    "uis_ig = np.argsort(uncertains_ig)[::-1]\n",
    "top10_uis_ig = uis_ig[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ig[0]\n",
    "print \"Actual label\", y_test[uis_ig[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ig[0]]\n",
    "print X_test_ss[uis_ig[0]]\n",
    "print X_test_ig[uis_ig[0]]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45 182  40  75 197 126 235 188  78 179]\n",
      "[111 182 197 186  58 151  45 179  40 172]\n",
      "[111  58 197 186 182  45  51  40 151  78]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 uncertain instances for each classifier\n",
    "\n",
    "print top10_uis_ori\n",
    "print top10_uis_ss\n",
    "print top10_uis_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  40\n",
      "Actual label 1\n",
      "[   3.     158.      76.      36.     245.      31.6      0.851   28.   ]\n",
      "[-0.25095213  1.16129525  0.35643175  0.96999799  1.43441893 -0.04982572\n",
      "  1.14499856 -0.44593516]\n",
      "[-0.81461204  0.9666254   0.34168138  0.4055599   1.0108045   0.49179541\n",
      "  1.5113965  -0.04042042]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  111\n",
      "Actual label 1\n",
      "[  0.00000000e+00   1.81000000e+02   8.80000000e+01   4.40000000e+01\n",
      "   5.10000000e+02   4.33000000e+01   2.22000000e-01   2.60000000e+01]\n",
      "[-1.14185152  1.88112959  0.97680475  1.47182248  3.73538635  1.43512945\n",
      " -0.75465609 -0.61611067]\n",
      "[-1.51285093  1.69555602  0.92742088  0.83815712  3.19744282  1.71605206\n",
      " -0.03818524 -0.2021021 ]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  111\n",
      "Actual label 1\n",
      "[  0.00000000e+00   1.81000000e+02   8.80000000e+01   4.40000000e+01\n",
      "   5.10000000e+02   4.33000000e+01   2.22000000e-01   2.60000000e+01]\n",
      "[-1.14185152  1.88112959  0.97680475  1.47182248  3.73538635  1.43512945\n",
      " -0.75465609 -0.61611067]\n",
      "[-1.51285093  1.69555602  0.92742088  0.83815712  3.19744282  1.71605206\n",
      " -0.03818524 -0.2021021 ]\n"
     ]
    }
   ],
   "source": [
    "# unc_ce from Top 10 uncertain instances\n",
    "\n",
    "min_evidence_top10_ori = np.min([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ce_ori = np.argmax(min_evidence_top10_ori)\n",
    "print \"Original: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ce_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ce_ori]]\n",
    "\n",
    "min_evidence_top10_ss = np.min([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ce_ss = np.argmax(min_evidence_top10_ss)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ce_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ce_ss]]\n",
    "\n",
    "min_evidence_top10_ig = np.min([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ce_ig = np.argmax(min_evidence_top10_ig)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ce_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ce_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  197\n",
      "Actual label 1\n",
      "[   4.     136.      70.       0.       0.      31.2      1.182   22.   ]\n",
      "[ 0.04601433  0.47275805  0.04624525 -1.28821221 -0.69289057 -0.10059342\n",
      "  2.14465784 -0.95646168]\n",
      "[-0.58186574  0.26938741  0.04881163 -1.54112761 -1.0108045   0.44994048\n",
      "  2.32683618 -0.52546546]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  186\n",
      "Actual label 0\n",
      "[   4.     154.      72.      29.     126.      31.3      0.338   37.   ]\n",
      "[ 0.04601433  1.03610667  0.14964075  0.53090156  0.40115431 -0.08790149\n",
      " -0.40432232  0.31985461]\n",
      "[-0.58186574  0.83985485  0.14643488  0.02703733  0.02888013  0.46040421\n",
      "  0.24758818  0.68714714]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  182\n",
      "Actual label 0\n",
      "[  10.     122.      78.      31.       0.      27.6      0.512   45.   ]\n",
      "[ 1.82781311  0.03459802  0.45982725  0.65635768 -0.69289057 -0.5575027\n",
      "  0.12117833  1.00055664]\n",
      "[ 0.81461204 -0.1743095   0.43930463  0.13518663 -1.0108045   0.07324612\n",
      "  0.67624831  1.33387385]\n"
     ]
    }
   ],
   "source": [
    "# unc_ie from Top 10 uncertain instances \n",
    "\n",
    "max_evidence_top10_ori = np.max([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ie_ori = np.argmin(max_evidence_top10_ori)\n",
    "print \"Original: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ie_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ie_ori]]\n",
    "\n",
    "max_evidence_top10_ss = np.max([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ie_ss = np.argmin(max_evidence_top10_ss)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ie_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ie_ss]]\n",
    "\n",
    "max_evidence_top10_ig = np.max([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ie_ig = np.argmin(max_evidence_top10_ig)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ie_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ie_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 145\n",
      "Actual label 1\n",
      "[   9.     171.     110.      24.     240.      45.4      0.721   54.   ]\n",
      "[ 1.53084665  1.56815814  2.11415525  0.21726125  1.39100445  1.70165987\n",
      "  0.75238313  1.76634642]\n",
      "[ 0.58186574  1.37862966  2.00127663 -0.24333594  0.96954718  1.93579043\n",
      "  1.19113318  2.06144141]\n",
      "\n",
      "Index of test: 0\n",
      "Actual label 1\n",
      "[   3.     173.      82.      48.     465.      38.4      2.137   25.   ]\n",
      "[-0.25095213  1.63075243  0.66661825  1.72273472  3.34465603  0.81322515\n",
      "  5.02887118 -0.70119842]\n",
      "[-0.81461204  1.44201494  0.63455113  1.05445573  2.82612688  1.20332919\n",
      "  4.67953978 -0.28294294]\n",
      "\n",
      "Index of test: 0\n",
      "Actual label 1\n",
      "[   3.     173.      82.      48.     465.      38.4      2.137   25.   ]\n",
      "[-0.25095213  1.63075243  0.66661825  1.72273472  3.34465603  0.81322515\n",
      "  5.02887118 -0.70119842]\n",
      "[-0.81461204  1.44201494  0.63455113  1.05445573  2.82612688  1.20332919\n",
      "  4.67953978 -0.28294294]\n"
     ]
    }
   ],
   "source": [
    "# Least negative among Top 10 possitive \n",
    "\n",
    "top_positive_index_ori = np.argsort(pos_evi_ori)[::-1]\n",
    "tp_ori = top_positive_index_ori[:10]\n",
    "neg_info_ori = neg_evi_ori[tp_ori]\n",
    "index_least_neg_ori = np.argmin(neg_info_ori)\n",
    "print \"Index of test:\",tp_ori[index_least_neg_ori]\n",
    "print \"Actual label\", y_test[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ori[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ss[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ig[tp_ori[index_least_neg_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ss = np.argsort(pos_evi_ss)[::-1]\n",
    "tp_ss = top_positive_index_ss[:10]\n",
    "neg_info_ss = neg_evi_ss[tp_ss]\n",
    "index_least_neg_ss = np.argmin(neg_info_ss)\n",
    "print \"Index of test:\",tp_ss[index_least_neg_ss]\n",
    "print \"Actual label\", y_test[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ori[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ss[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ig[tp_ss[index_least_neg_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ig = np.argsort(pos_evi_ig)[::-1]\n",
    "tp_ig = top_positive_index_ig[:10]\n",
    "neg_info_ig = neg_evi_ig[tp_ig]\n",
    "index_least_neg_ig = np.argmin(neg_info_ig)\n",
    "print \"Index of test:\",tp_ig[index_least_neg_ig]\n",
    "print \"Actual label\", y_test[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ori[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ss[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ig[tp_ig[index_least_neg_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199   6 145   0 247  53  39 206 220 207]\n",
      "[199  39   0   6 145 247  53 220  23 233]\n",
      "[199   0  39 145   6  23  53 233 247 139]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 positive based on positive evidence\n",
    "\n",
    "print tp_ori\n",
    "print tp_ss\n",
    "print tp_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 208\n",
      "Actual label 1\n",
      "[   7.     168.      88.      42.     321.      38.2      0.787   40.   ]\n",
      "[ 0.93691372  1.4742667   0.97680475  1.34636635  2.09431902  0.7878413\n",
      "  0.95171097  0.57511787]\n",
      "[ 0.11637315  1.28355176  0.92742088  0.73000782  1.63791587  1.18240172\n",
      "  1.35372841  0.92966966]\n",
      "\n",
      "Index of test: 244\n",
      "Actual label 0\n",
      "[  1.     71.     62.      0.      0.     21.8     0.416  26.   ]\n",
      "[-0.84488505 -1.5615564  -0.36733675 -1.28821221 -0.69289057 -1.29363432\n",
      " -0.16875306 -0.61611067]\n",
      "[-1.28010463 -1.79063393 -0.34168138 -1.54112761 -1.0108045  -0.53365033\n",
      "  0.43974617 -0.2021021 ]\n",
      "\n",
      "Index of test: 171\n",
      "Actual label 0\n",
      "[   1.      96.     122.       0.       0.      22.4      0.207   27.   ]\n",
      "[-0.84488505 -0.77912776  2.73452825 -1.28821221 -0.69289057 -1.21748278\n",
      " -0.79995787 -0.53102292]\n",
      "[-1.28010463 -0.99831803  2.58701614 -1.54112761 -1.0108045  -0.47086794\n",
      " -0.0751387  -0.12126126]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Least positive among Top 10 negative instances\n",
    "\n",
    "top_negative_index_ori = np.argsort(abs(neg_evi_ori))[::-1]\n",
    "tn_ori = top_negative_index_ori[:10]\n",
    "pos_info_ori = pos_evi_ori[tp_ori]\n",
    "index_least_pos_ori = np.argmin(pos_info_ori)\n",
    "print \"Index of test:\",tn_ori[index_least_pos_ori]\n",
    "print \"Actual label\", y_test[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ori[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ss[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ig[tn_ori[index_least_pos_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ss = np.argsort(abs(neg_evi_ss))[::-1]\n",
    "tn_ss = top_negative_index_ss[:10]\n",
    "pos_info_ss = pos_evi_ss[tp_ss]\n",
    "index_least_pos_ss = np.argmin(pos_info_ss)\n",
    "print \"Index of test:\",tn_ss[index_least_pos_ss]\n",
    "print \"Actual label\", y_test[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ori[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ss[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ig[tn_ss[index_least_pos_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ig = np.argsort(abs(neg_evi_ig))[::-1]\n",
    "tn_ig = top_negative_index_ig[:10]\n",
    "pos_info_ig = pos_evi_ig[tp_ig]\n",
    "index_least_pos_ig = np.argmin(pos_info_ig)\n",
    "print \"Index of test:\",tn_ig[index_least_pos_ig]\n",
    "print \"Actual label\", y_test[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ori[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ss[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ig[tn_ig[index_least_pos_ig]]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145 111 160  87  74 171   0 118 220 208]\n",
      "[238 204 152  10 213 201  19 171 165 244]\n",
      "[238 204  10 152 213 201  19 244 165 171]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 negative based on negative evidence\n",
    "\n",
    "print tn_ori\n",
    "print tn_ss\n",
    "print tn_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
