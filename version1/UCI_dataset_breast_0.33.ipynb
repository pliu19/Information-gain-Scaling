{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "from classifiers import TransparentLogisticRegression\n",
    "from matplotlib import pylab as pl\n",
    "from scipy.sparse import diags\n",
    "from IPython import display\n",
    "from scale import decision_tree_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# breast-w\n",
    "# source link: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29\n",
    "# relevant paper: Multisurface method of pattern separation for medical diagnosis applied to breast cytology\n",
    "\n",
    "dataset = \"breast-w.csv\"\n",
    "class_index = 9\n",
    "num_cols = 10\n",
    "classes = ['benign', 'malignant']\n",
    "read_cols = [i for i in range(num_cols) if i != class_index]\n",
    "file_path = \"D:\\\\IIT_Master\\\\2016 Spring\\\\CS597\\\\uci\\\\uci\\\\uci-tar\\\\nominal\\\\\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clump_Thickness' 'Cell_Size_Uniformity' 'Cell_Shape_Uniformity'\n",
      " 'Marginal_Adhesion' 'Single_Epi_Cell_Size' 'Bare_Nuclei' 'Bland_Chromatin'\n",
      " 'Normal_Nucleoli' 'Mitoses' 'Class\\n']\n"
     ]
    }
   ],
   "source": [
    "# ['Clump_Thickness' 'Cell_Size_Uniformity' 'Cell_Shape_Uniformity' 'Marginal_Adhesion' 'Single_Epi_Cell_Size' 'Bare_Nuclei' 'Bland_Chromatin'\n",
    "#  'Normal_Nucleoli' 'Mitoses' \n",
    "\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline()\n",
    "    #print header\n",
    "    #header = np.fromstring(\"a, b\", dtype=np.str_, sep=',')\n",
    "    header = np.array(header.split(','))\n",
    "    feature_names = header[read_cols]\n",
    "    \n",
    "    print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (699L, 9L)\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "# Loading the data and splitting the train, test\n",
    "\n",
    "X = np.loadtxt(file_path, dtype=float, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=read_cols)\n",
    "y = np.loadtxt(file_path, dtype=int, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=(class_index,), converters={class_index: lambda x: classes.index(x)})\n",
    "\n",
    "num_inst, num_feat = np.shape(X)\n",
    "print \"The shape of X:\",np.shape(X)\n",
    "\n",
    "ss = ShuffleSplit(num_inst, n_iter=1, test_size=0.33, random_state=2)\n",
    "\n",
    "for i, j in ss:\n",
    "    train_index = i \n",
    "    test_index = j\n",
    "    \n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine binary features\n",
    "num_features = X.shape[1]\n",
    "non_binary = []\n",
    "binary = []\n",
    "for i in range(num_features):\n",
    "    if len(np.unique(X[:,i])) != 2:\n",
    "        non_binary.append(i)\n",
    "    else:\n",
    "        binary.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Scale for non_binary features -- Train\n",
      "IG Scale for non_binary features -- Test\n"
     ]
    }
   ],
   "source": [
    "# Original features\n",
    "X_original = np.copy(X)\n",
    "\n",
    "X_train_ori = X_original[train_index]\n",
    "X_test_ori = X_original[test_index]\n",
    "\n",
    "# Standard scale non binary features\n",
    "# X_ss = scale(X)\n",
    "X_ss = np.copy(X)\n",
    "\n",
    "if len(non_binary) > 0:\n",
    "    X_ss[:,non_binary]=scale(X[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_ss[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_ss[:,binary] = X_b\n",
    "    \n",
    "X_train_ss = X_ss[train_index]\n",
    "X_test_ss = X_ss[test_index]\n",
    "\n",
    "# Information gain scaling non binary features\n",
    "\n",
    "X_ig = np.copy(X_original)\n",
    "scale_ = decision_tree_scale()\n",
    "\n",
    "X_train_ig = X_ig[train_index]\n",
    "X_test_ig = X_ig[test_index]\n",
    "\n",
    "if len(non_binary) > 0: \n",
    "    print \"IG Scale for non_binary features -- Train\"\n",
    "    X_train_ig[:,non_binary]=scale_.fit_transform(X_train_ig[:,non_binary], y_train)\n",
    "\n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_train_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_train_ig[:,binary] = X_b\n",
    "    \n",
    "if len(non_binary) > 0:\n",
    "    \n",
    "    print \"IG Scale for non_binary features -- Test\"\n",
    "    X_test_ig[:,non_binary]=scale_.transform(X_test_ig[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0:\n",
    "    \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_test_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_test_ig[:,binary] = X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of each features:\n",
      "[ 4.41773963  3.13447783  3.2074392   2.80686695  3.21602289  3.54465593\n",
      "  3.43776824  2.86695279  1.58941345]\n",
      "The best splitting of each features\n",
      "[ 6.5       3.5       2.5       3.5       2.5       3.772328  3.5       2.5\n",
      "  1.5     ]\n"
     ]
    }
   ],
   "source": [
    "print \"The mean of each features:\"\n",
    "print np.mean(X, axis=0)\n",
    "print \"The best splitting of each features\"\n",
    "print scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_ori = TransparentLogisticRegression()\n",
    "clf_ss = TransparentLogisticRegression()\n",
    "clf_ig = TransparentLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransparentLogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "               fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "               multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "               random_state=None, solver='liblinear', tol=0.0001,\n",
       "               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit train instances for each classifier\n",
    "\n",
    "clf_ori.fit(X_train_ori, y_train)\n",
    "clf_ss.fit(X_train_ss, y_train)\n",
    "clf_ig.fit(X_train_ig, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22088908  0.26175129  0.31642554  0.21939307 -0.14757989  0.26928452\n",
      "   0.09284733  0.18771492  0.10474278]]\n",
      "[[ 1.39332688  0.45631339  0.87784037  1.01793815  0.18089409  0.96441086\n",
      "   0.78996617  0.48458817  0.53051557]]\n",
      "[[ 1.67856393  0.51565334  0.9059625   1.02612456  0.20494585  1.00186121\n",
      "   0.79942117  0.51108833  0.53930884]]\n",
      "\n",
      "[-5.6638487]\n",
      "[-1.18090226]\n",
      "[-0.24227209]\n"
     ]
    }
   ],
   "source": [
    "# print the weights for each classifiers\n",
    "\n",
    "print clf_ori.coef_\n",
    "print clf_ss.coef_\n",
    "print clf_ig.coef_\n",
    "print \"\"\n",
    "\n",
    "print clf_ori.intercept_ \n",
    "print clf_ss.intercept_ \n",
    "print clf_ig.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939393939394\n",
      "0.948051948052\n",
      "0.943722943723\n"
     ]
    }
   ],
   "source": [
    "# Predict test instances for each classifier\n",
    "\n",
    "y_predict_ori = clf_ori.predict(X_test_ori)\n",
    "y_pred_prob_ori = clf_ori.predict_proba(X_test_ori)\n",
    "neg_evi_ori, pos_evi_ori = clf_ori.predict_evidences(X_test_ori)\n",
    "\n",
    "y_predict_ss = clf_ss.predict(X_test_ss)\n",
    "y_pred_prob_ss = clf_ss.predict_proba(X_test_ss)\n",
    "neg_evi_ss, pos_evi_ss = clf_ss.predict_evidences(X_test_ss)\n",
    "\n",
    "y_predict_ig = clf_ig.predict(X_test_ig)\n",
    "y_pred_prob_ig = clf_ig.predict_proba(X_test_ig)\n",
    "neg_evi_ig, pos_evi_ig = clf_ig.predict_evidences(X_test_ig)\n",
    "\n",
    "print accuracy_score(y_test,y_predict_ori)\n",
    "print accuracy_score(y_test,y_predict_ss)\n",
    "print accuracy_score(y_test,y_predict_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(benign) instances based on probability\n",
      "Index of test:  41\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.   1.   1.   1.  10.   1.   1.   1.   1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716  3.06590584 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583  3.11386136 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n",
      "Standard scaling: Most negative(benign) instances based on probability\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583 -0.62277227 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n",
      "Information gain scaling: Most negative(benign) instances based on probability\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583 -0.62277227 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"benign\" -- Probability\n",
    "\n",
    "Most_negative_1 = np.argmax(y_pred_prob_ori[:,0])\n",
    "print \"Original: Most negative(benign) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_1]\n",
    "print X_test_ss[Most_negative_1]\n",
    "print X_test_ig[Most_negative_1]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_2 = np.argmax(y_pred_prob_ss[:,0])\n",
    "print \"Standard scaling: Most negative(benign) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_2]\n",
    "print X_test_ss[Most_negative_2]\n",
    "print X_test_ig[Most_negative_2]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_3 = np.argmax(y_pred_prob_ig[:,0])\n",
    "print \"Information gain scaling: Most negative(benign) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_3]\n",
    "print X_test_ss[Most_negative_3]\n",
    "print X_test_ig[Most_negative_3]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(malignant) instances based on probability\n",
      "Index of test:  102\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   7.  10.   7.  10.   4.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  1.71010564  1.79351268\n",
      "  1.46195655  2.33759359  1.40653241]\n",
      "[ 0.99480786  2.05044816  2.32857147  2.21422715  1.86831682  1.70634827\n",
      "  1.42405927  2.3842226   1.36104308]\n",
      "\n",
      "Standard scaling: Most positive(malignant) instances based on probability\n",
      "Index of test:  102\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   7.  10.   7.  10.   4.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  1.71010564  1.79351268\n",
      "  1.46195655  2.33759359  1.40653241]\n",
      "[ 0.99480786  2.05044816  2.32857147  2.21422715  1.86831682  1.70634827\n",
      "  1.42405927  2.3842226   1.36104308]\n",
      "\n",
      "Information gain scaling: Most positive(malignant) instances based on probability\n",
      "Index of test:  102\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   7.  10.   7.  10.   4.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  1.71010564  1.79351268\n",
      "  1.46195655  2.33759359  1.40653241]\n",
      "[ 0.99480786  2.05044816  2.32857147  2.21422715  1.86831682  1.70634827\n",
      "  1.42405927  2.3842226   1.36104308]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"malignant\" -- Probability\n",
    "\n",
    "Most_positive_1 = np.argmax(y_pred_prob_ori[:,1])\n",
    "\n",
    "\n",
    "print \"Original: Most positive(malignant) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_1]\n",
    "print X_test_ss[Most_positive_1]\n",
    "print X_test_ig[Most_positive_1]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_2 = np.argmax(y_pred_prob_ss[:,1])\n",
    "print \"Standard scaling: Most positive(malignant) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_2]\n",
    "print X_test_ss[Most_positive_2]\n",
    "print X_test_ig[Most_positive_2]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_3 = np.argmax(y_pred_prob_ig[:,1])\n",
    "print \"Information gain scaling: Most positive(malignant) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_3]\n",
    "print X_test_ss[Most_positive_3]\n",
    "print X_test_ig[Most_positive_3]\n",
    "print \"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(benign) instances based on evidence\n",
      "Index of test:  1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  7.   6.   4.   8.  10.  10.   9.   5.   3.]\n",
      "[ 0.91773703  0.93973866  0.2668747   1.82002154  3.06590584  1.79351268\n",
      "  2.28276589  0.69902769  0.82305101]\n",
      "[ 0.14211541  0.78863391  0.46571429  1.53292649  3.11386136  1.70634827\n",
      "  2.23780743  0.79474087  0.81662585]\n",
      "\n",
      "Standard scaling: Most negative(benign) instances based on evidence\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583 -0.62277227 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n",
      "Information gain scaling: Most negative(benign) instances based on evidence\n",
      "Index of test:  32\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -1.00149476 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583 -0.62277227 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"benign\" -- Evidence\n",
    "\n",
    "negative_evi_index_ori = np.argmax(abs(neg_evi_ori))\n",
    "print \"Original: Most negative(benign) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ori]\n",
    "print X_test_ss[negative_evi_index_ori]\n",
    "print X_test_ig[negative_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ss = np.argmax(abs(neg_evi_ss))\n",
    "print \"Standard scaling: Most negative(benign) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ss]\n",
    "print X_test_ss[negative_evi_index_ss]\n",
    "print X_test_ig[negative_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ig = np.argmax(abs(neg_evi_ig))\n",
    "print \"Information gain scaling: Most negative(benign) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ig]\n",
    "print X_test_ss[negative_evi_index_ig]\n",
    "print X_test_ig[negative_evi_index_ig]\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(malignant) instances based on evidence\n",
      "Index of test:  102\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   7.  10.   7.  10.   4.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  1.71010564  1.79351268\n",
      "  1.46195655  2.33759359  1.40653241]\n",
      "[ 0.99480786  2.05044816  2.32857147  2.21422715  1.86831682  1.70634827\n",
      "  1.42405927  2.3842226   1.36104308]\n",
      "\n",
      "Standard scaling: Most positive(malignant) instances based on evidence\n",
      "Index of test:  102\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   7.  10.   7.  10.   4.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  1.71010564  1.79351268\n",
      "  1.46195655  2.33759359  1.40653241]\n",
      "[ 0.99480786  2.05044816  2.32857147  2.21422715  1.86831682  1.70634827\n",
      "  1.42405927  2.3842226   1.36104308]\n",
      "\n",
      "Information gain scaling: Most positive(malignant) instances based on evidence\n",
      "Index of test:  102\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.  10.  10.  10.   7.  10.   7.  10.   4.]\n",
      "[ 1.983939    2.25152563  2.28722218  2.52095546  1.71010564  1.79351268\n",
      "  1.46195655  2.33759359  1.40653241]\n",
      "[ 0.99480786  2.05044816  2.32857147  2.21422715  1.86831682  1.70634827\n",
      "  1.42405927  2.3842226   1.36104308]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"mallignant\" -- Evidence \n",
    "\n",
    "positive_evi_index_ori = np.argmax(pos_evi_ori)\n",
    "print \"Original: Most positive(malignant) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ori]\n",
    "print X_test_ss[positive_evi_index_ori]\n",
    "print X_test_ig[positive_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ss = np.argmax(pos_evi_ss)\n",
    "print \"Standard scaling: Most positive(malignant) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ss]\n",
    "print X_test_ss[positive_evi_index_ss]\n",
    "print X_test_ig[positive_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ig = np.argmax(pos_evi_ig)\n",
    "print \"Information gain scaling: Most positive(malignant) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ig]\n",
    "print X_test_ss[positive_evi_index_ig]\n",
    "print X_test_ig[positive_evi_index_ig]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most uncertain instance based on probability\n",
      "Index of test:  199\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 3.  4.  5.  2.  6.  8.  4.  1.  1.]\n",
      "[-0.50386559  0.28384518  0.60359928 -0.28278021  1.25817224  1.23784511\n",
      "  0.23074254 -0.61182504 -0.34391178]\n",
      "[-0.99480786  0.15772678  0.77619049 -0.5109755   1.4531353   1.15835914\n",
      "  0.20343704 -0.47684452 -0.27220862]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  0\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[ 10.   2.   2.   1.   2.   6.   1.   1.   2.]\n",
      "[ 1.983939   -0.37204831 -0.40657446 -0.63324716 -0.54956136  0.68217754\n",
      " -1.00047147 -0.61182504  0.23956962]\n",
      "[ 0.99480786 -0.47318034 -0.1552381  -0.85162583 -0.20759076  0.61037002\n",
      " -1.0171852  -0.47684452  0.27220862]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  191\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  5.   2.   3.   1.   6.  10.   5.   1.   1.]\n",
      "[ 0.20693572 -0.37204831 -0.06984988 -0.63324716  1.25817224  1.79351268\n",
      "  0.64114721 -0.61182504 -0.34391178]\n",
      "[-0.42634622 -0.47318034  0.1552381  -0.85162583  1.4531353   1.70634827\n",
      "  0.61031112 -0.47684452 -0.27220862]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unc_1 Top 1 uncertain instances\n",
    "\n",
    "uncertains_ori = np.min(y_pred_prob_ori, axis=1)\n",
    "uis_ori = np.argsort(uncertains_ori)[::-1]\n",
    "top10_uis_ori = uis_ori[:10]\n",
    "print \"Original: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ori[0]\n",
    "print \"Actual label\", y_test[uis_ori[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ori[0]]\n",
    "print X_test_ss[uis_ori[0]]\n",
    "print X_test_ig[uis_ori[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ss = np.min(y_pred_prob_ss, axis=1)\n",
    "uis_ss = np.argsort(uncertains_ss)[::-1]\n",
    "top10_uis_ss = uis_ss[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ss[0]\n",
    "print \"Actual label\", y_test[uis_ss[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ss[0]]\n",
    "print X_test_ss[uis_ss[0]]\n",
    "print X_test_ig[uis_ss[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ig = np.min(y_pred_prob_ig, axis=1)\n",
    "uis_ig = np.argsort(uncertains_ig)[::-1]\n",
    "top10_uis_ig = uis_ig[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ig[0]\n",
    "print \"Actual label\", y_test[uis_ig[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ig[0]]\n",
    "print X_test_ss[uis_ig[0]]\n",
    "print X_test_ig[uis_ig[0]]\n",
    "print \"\"\n",
    "\n",
    "# print scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199 159  31 178   0  13 191 154 135 207]\n",
      "[  0 191 199 227  13 116 178 207 126  84]\n",
      "[191   0 227 178  13 199 116  84 126 184]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 uncertain instances for each classifier\n",
    "\n",
    "print top10_uis_ori\n",
    "print top10_uis_ss\n",
    "print top10_uis_ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  31\n",
      "Actual label 1\n",
      "[ 7.  4.  6.  4.  6.  1.  4.  3.  1.]\n",
      "[ 0.91773703  0.28384518  0.94032386  0.41815371  1.25817224 -0.70699139\n",
      "  0.23074254  0.04360132 -0.34391178]\n",
      "[ 0.14211541  0.15772678  1.08666669  0.17032517  1.4531353  -0.7596028\n",
      "  0.20343704  0.15894817 -0.27220862]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  0\n",
      "Actual label 1\n",
      "[ 10.   2.   2.   1.   2.   6.   1.   1.   2.]\n",
      "[ 1.983939   -0.37204831 -0.40657446 -0.63324716 -0.54956136  0.68217754\n",
      " -1.00047147 -0.61182504  0.23956962]\n",
      "[ 0.99480786 -0.47318034 -0.1552381  -0.85162583 -0.20759076  0.61037002\n",
      " -1.0171852  -0.47684452  0.27220862]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  84\n",
      "Actual label 1\n",
      "[  3.   3.   5.   2.   3.  10.   7.   1.   1.]\n",
      "[-0.50386559 -0.04410156  0.60359928 -0.28278021 -0.09762796  1.79351268\n",
      "  1.46195655 -0.61182504 -0.34391178]\n",
      "[-0.99480786 -0.15772678  0.77619049 -0.5109755   0.20759076  1.70634827\n",
      "  1.42405927 -0.47684452 -0.27220862]\n"
     ]
    }
   ],
   "source": [
    "# unc_ce from Top 10 uncertain instances\n",
    "\n",
    "min_evidence_top10_ori = np.min([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ce_ori = np.argmax(min_evidence_top10_ori)\n",
    "print \"Original: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ce_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ce_ori]]\n",
    "\n",
    "min_evidence_top10_ss = np.min([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ce_ss = np.argmax(min_evidence_top10_ss)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ce_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ce_ss]]\n",
    "\n",
    "min_evidence_top10_ig = np.min([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ce_ig = np.argmax(min_evidence_top10_ig)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ce_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ce_ig]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  159\n",
      "Actual label 1\n",
      "[ 2.  3.  4.  4.  2.  5.  2.  5.  1.]\n",
      "[-0.85926625 -0.04410156  0.2668747   0.41815371 -0.54956136  0.40434375\n",
      " -0.5900668   0.69902769 -0.34391178]\n",
      "[-1.27903867 -0.15772678  0.46571429  0.17032517 -0.20759076  0.33637545\n",
      " -0.61031112  0.79474087 -0.27220862]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  116\n",
      "Actual label 0\n",
      "[ 6.  3.  3.  3.  3.  2.  6.  1.  1.]\n",
      "[ 0.56233637 -0.04410156 -0.06984988  0.06768675 -0.09762796 -0.4291576\n",
      "  1.05155188 -0.61182504 -0.34391178]\n",
      "[-0.14211541 -0.15772678  0.1552381  -0.17032517  0.20759076 -0.48560824\n",
      "  1.0171852  -0.47684452 -0.27220862]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  116\n",
      "Actual label 0\n",
      "[ 6.  3.  3.  3.  3.  2.  6.  1.  1.]\n",
      "[ 0.56233637 -0.04410156 -0.06984988  0.06768675 -0.09762796 -0.4291576\n",
      "  1.05155188 -0.61182504 -0.34391178]\n",
      "[-0.14211541 -0.15772678  0.1552381  -0.17032517  0.20759076 -0.48560824\n",
      "  1.0171852  -0.47684452 -0.27220862]\n"
     ]
    }
   ],
   "source": [
    "# unc_ie from Top 10 uncertain instances \n",
    "\n",
    "max_evidence_top10_ori = np.max([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ie_ori = np.argmin(max_evidence_top10_ori)\n",
    "print \"Original: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ie_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ie_ori]]\n",
    "\n",
    "max_evidence_top10_ss = np.max([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ie_ss = np.argmin(max_evidence_top10_ss)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ie_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ie_ss]]\n",
    "\n",
    "max_evidence_top10_ig = np.max([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ie_ig = np.argmin(max_evidence_top10_ig)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ie_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ie_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 187\n",
      "Actual label 1\n",
      "[ 10.   8.   8.   2.   8.  10.   4.   8.  10.]\n",
      "[ 1.983939    1.59563215  1.61377302 -0.28278021  2.16203904  1.79351268\n",
      "  0.23074254  1.68216723  4.9074208 ]\n",
      "[ 0.99480786  1.41954103  1.70761908 -0.5109755   2.28349833  1.70634827\n",
      "  0.20343704  1.7484299   4.62754646]\n",
      "\n",
      "Index of test: 187\n",
      "Actual label 1\n",
      "[ 10.   8.   8.   2.   8.  10.   4.   8.  10.]\n",
      "[ 1.983939    1.59563215  1.61377302 -0.28278021  2.16203904  1.79351268\n",
      "  0.23074254  1.68216723  4.9074208 ]\n",
      "[ 0.99480786  1.41954103  1.70761908 -0.5109755   2.28349833  1.70634827\n",
      "  0.20343704  1.7484299   4.62754646]\n",
      "\n",
      "Index of test: 77\n",
      "Actual label 1\n",
      "[  3.   5.   7.   8.   8.   9.   7.  10.   7.]\n",
      "[-0.50386559  0.61179192  1.27704844  1.82002154  2.16203904  1.51567889\n",
      "  1.46195655  2.33759359  3.15697661]\n",
      "[-0.99480786  0.47318034  1.39714288  1.53292649  2.28349833  1.4323537\n",
      "  1.42405927  2.3842226   2.99429477]\n"
     ]
    }
   ],
   "source": [
    "# Least negative among Top 10 possitive \n",
    "\n",
    "top_positive_index_ori = np.argsort(pos_evi_ori)[::-1]\n",
    "tp_ori = top_positive_index_ori[:10]\n",
    "neg_info_ori = neg_evi_ori[tp_ori]\n",
    "index_least_neg_ori = np.argmin(neg_info_ori)\n",
    "print \"Index of test:\",tp_ori[index_least_neg_ori]\n",
    "print \"Actual label\", y_test[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ori[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ss[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ig[tp_ori[index_least_neg_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ss = np.argsort(pos_evi_ss)[::-1]\n",
    "tp_ss = top_positive_index_ss[:10]\n",
    "neg_info_ss = neg_evi_ss[tp_ss]\n",
    "index_least_neg_ss = np.argmin(neg_info_ss)\n",
    "print \"Index of test:\",tp_ss[index_least_neg_ss]\n",
    "print \"Actual label\", y_test[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ori[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ss[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ig[tp_ss[index_least_neg_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ig = np.argsort(pos_evi_ig)[::-1]\n",
    "tp_ig = top_positive_index_ig[:10]\n",
    "neg_info_ig = neg_evi_ig[tp_ig]\n",
    "index_least_neg_ig = np.argmin(neg_info_ig)\n",
    "print \"Index of test:\",tp_ig[index_least_neg_ig]\n",
    "print \"Actual label\", y_test[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ori[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ss[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ig[tp_ig[index_least_neg_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102 166  62  60  28 193 187 163 181 214]\n",
      "[102 166  60 187 193  33  28  62 214   8]\n",
      "[102 166  60 193 187  62  28  33  77 221]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 positive based on positive evidence\n",
    "\n",
    "print tp_ori\n",
    "print tp_ss\n",
    "print tp_ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 69\n",
      "Actual label 1\n",
      "[  5.   3.   4.   1.   8.  10.   4.   9.   1.]\n",
      "[ 0.20693572 -0.04410156  0.2668747  -0.63324716  2.16203904  1.79351268\n",
      "  0.23074254  2.00988041 -0.34391178]\n",
      "[-0.42634622 -0.15772678  0.46571429 -0.85162583  2.28349833  1.70634827\n",
      "  0.20343704  2.06632625 -0.27220862]\n",
      "\n",
      "Index of test: 97\n",
      "Actual label 0\n",
      "[ 1.  1.  1.  1.  2.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -0.54956136 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583 -0.20759076 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n",
      "Index of test: 120\n",
      "Actual label 0\n",
      "[ 1.  1.  1.  1.  2.  1.  1.  1.  1.]\n",
      "[-1.2146669  -0.69999505 -0.74329904 -0.63324716 -0.54956136 -0.70699139\n",
      " -1.00047147 -0.61182504 -0.34391178]\n",
      "[-1.56326949 -0.78863391 -0.46571429 -0.85162583 -0.20759076 -0.7596028\n",
      " -1.0171852  -0.47684452 -0.27220862]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Least positive among Top 10 negative instances\n",
    "\n",
    "top_negative_index_ori = np.argsort(abs(neg_evi_ori))[::-1]\n",
    "tn_ori = top_negative_index_ori[:10]\n",
    "pos_info_ori = pos_evi_ori[tp_ori]\n",
    "index_least_pos_ori = np.argmin(pos_info_ori)\n",
    "print \"Index of test:\",tn_ori[index_least_pos_ori]\n",
    "print \"Actual label\", y_test[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ori[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ss[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ig[tn_ori[index_least_pos_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ss = np.argsort(abs(neg_evi_ss))[::-1]\n",
    "tn_ss = top_negative_index_ss[:10]\n",
    "pos_info_ss = pos_evi_ss[tp_ss]\n",
    "index_least_pos_ss = np.argmin(pos_info_ss)\n",
    "print \"Index of test:\",tn_ss[index_least_pos_ss]\n",
    "print \"Actual label\", y_test[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ori[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ss[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ig[tn_ss[index_least_pos_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ig = np.argsort(abs(neg_evi_ig))[::-1]\n",
    "tn_ig = top_negative_index_ig[:10]\n",
    "pos_info_ig = pos_evi_ig[tp_ig]\n",
    "index_least_pos_ig = np.argmin(pos_info_ig)\n",
    "print \"Index of test:\",tn_ig[index_least_pos_ig]\n",
    "print \"Actual label\", y_test[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ori[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ss[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ig[tn_ig[index_least_pos_ig]]\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121 200   1 139 164  42 205  41 160  69]\n",
      "[ 32 127 180 208 192  10 170 120  95  97]\n",
      "[127  32 180  10 192 170 208  97  95 120]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 negative based on negative evidence\n",
    "\n",
    "print tn_ori\n",
    "print tn_ss\n",
    "print tn_ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
