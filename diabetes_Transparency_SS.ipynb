{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from classifiers import TransparentLogisticRegression\n",
    "from matplotlib import pylab as pl\n",
    "from scipy.sparse import diags\n",
    "from IPython import display\n",
    "from scale import decision_tree_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diabetes\n",
    "dataset = \"diabetes.csv\"\n",
    "class_index = 8\n",
    "num_cols = 9\n",
    "classes= ['tested_negative', 'tested_positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_cols = [i for i in range(num_cols) if i != class_index]\n",
    "file_path = \"D:\\\\IIT_Master\\\\2016 Spring\\\\CS597\\\\uci\\\\uci\\\\uci-tar\\\\nominal\\\\\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age' 'class\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline()\n",
    "    #print header\n",
    "    #header = np.fromstring(\"a, b\", dtype=np.str_, sep=',')\n",
    "    header = np.array(header.split(','))\n",
    "    feature_names = header[read_cols]\n",
    "    \n",
    "    print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.loadtxt(file_path, dtype=float, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=read_cols)\n",
    "y = np.loadtxt(file_path, dtype=int, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=(class_index,), converters={class_index: lambda x: classes.index(x)})\n",
    "\n",
    "X_train_, X_keep_test, y_train_, y_test_ = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X = scale(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine binary features\n",
    "num_features = X.shape[1]\n",
    "non_binary = []\n",
    "binary = []\n",
    "for i in range(num_features):\n",
    "    if len(np.unique(X[:,i])) != 2:\n",
    "        non_binary.append(i)\n",
    "    else:\n",
    "        binary.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Scaling the train instances\n",
    "\n",
    "print y[0]\n",
    "\n",
    "X_n = X.copy()\n",
    "\n",
    "if len(non_binary) > 0:\n",
    "    X_n[:,non_binary]=scale(X[:,non_binary])\n",
    "    \n",
    "\n",
    "# for binary features, replace zeros with -1, assuming the other values are 1; a more correct way would check if this was true.\n",
    "if len(binary) > 0:\n",
    "    X_b = X_n[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_n[:,binary] = X_b\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_n, y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransparentLogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "               fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "               multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "               random_state=None, solver='liblinear', tol=0.0001,\n",
       "               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = TransparentLogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prediction = clf.predict(X_test)\n",
    "neg_evi, pos_evi = clf. predict_evidences(X_test)\n",
    "y_prediction_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  11.     135.       0.       0.       0.      52.3      0.578   40.   ]\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"tested_positive\" -- Probability\n",
    "\n",
    "Most_positive = np.argmax(y_prediction_proba[:,1])\n",
    "\n",
    "print X_keep_test[Most_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.      0.     74.     20.     23.     27.7     0.299  21.   ]\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"tested_negative\" -- Probability\n",
    "\n",
    "Most_negative = np.argmax(y_prediction_proba[:,0])\n",
    "\n",
    "print X_keep_test[Most_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.     173.      78.      32.     265.      46.5      1.159   58.   ]\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"tested_positive\" -- Evidence \n",
    "\n",
    "positive_evi_index = np.argmax(pos_evi)\n",
    "\n",
    "print X_keep_test[positive_evi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.     74.      0.      0.      0.      0.      0.102  22.   ]\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"tested_negative\" -- Evidence\n",
    "\n",
    "negative_evi_index = np.argmax(abs(neg_evi))\n",
    "\n",
    "# print neg_evi[]\n",
    "\n",
    "print X_keep_test[negative_evi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.     135.      68.      42.     250.      42.3      0.365   24.   ]\n"
     ]
    }
   ],
   "source": [
    "# unc_1 Top 1 uncertain instances\n",
    "\n",
    "uncertains = np.min(y_prediction_proba, axis=1)\n",
    "\n",
    "uis = np.argsort(uncertains)[::-1]\n",
    "\n",
    "top_10_uis = uis[:10]\n",
    "\n",
    "print X_keep_test[uis[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  13.     145.      82.      19.     110.      22.2      0.245   57.   ]\n"
     ]
    }
   ],
   "source": [
    "# unc_ce from Top 10 uncertain instances\n",
    "# print top_10_uis\n",
    "\n",
    "# min the evidence, then argmax to find the most conflicted instances among top 10 uncertain instances\n",
    "\n",
    "min_evidence_top_10 = np.min([abs(neg_evi[top_10_uis]),abs(pos_evi[top_10_uis])], axis=0 )\n",
    "\n",
    "index_ce = np.argmax(min_evidence_top_10)\n",
    "\n",
    "# print min_evidence_top_10\n",
    "# print index_ce\n",
    "# print top_10_uis[index_ce]\n",
    "\n",
    "print X_keep_test[top_10_uis[index_ce]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   9.     122.      56.       0.       0.      33.3      1.114   33.   ]\n"
     ]
    }
   ],
   "source": [
    "# unc_ie from Top 10 uncertain instances \n",
    "\n",
    "# max the nag/pos evidence, then argmin to find least conflicted instances among top 10 uncertain instances\n",
    "\n",
    "max_evidence_top_10 = np.max([abs(neg_evi[top_10_uis]),abs(pos_evi[top_10_uis])], axis=0 )\n",
    "\n",
    "index_ie = np.argmin(min_evidence_top_10)\n",
    "\n",
    "# print min_evidence_top_10\n",
    "# print index_ie\n",
    "# print top_10_uis[index_ie]\n",
    "\n",
    "print X_keep_test[top_10_uis[index_ie]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  11.     135.       0.       0.       0.      52.3      0.578   40.   ]]\n"
     ]
    }
   ],
   "source": [
    "# Least negative among Top 10 possitive \n",
    "\n",
    "top_positive_index = np.argsort(pos_evi)[::-1]\n",
    "\n",
    "# print neg_evi[top_possitive_index]\n",
    "\n",
    "tp = top_positive_index[:10]\n",
    "\n",
    "# Negative information\n",
    "\n",
    "# print pos_evi[tp]\n",
    "# print neg_evi[tp]\n",
    "\n",
    "neg_info = neg_evi[tp]\n",
    "\n",
    "least_neg_index = np.argwhere(neg_info == np.amax(neg_info))\n",
    "\n",
    "least_neg_index = least_neg_index.flatten().tolist()\n",
    "\n",
    "# print neg_info[least_neg_index]\n",
    "\n",
    "print X_keep_test[tp[least_neg_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.      0.     74.     20.     23.     27.7     0.299  21.   ]]\n"
     ]
    }
   ],
   "source": [
    "# Least positive among Top 10 negative instances\n",
    "\n",
    "top_negative_index = np.argsort(abs(neg_evi))[::-1]\n",
    "tp = top_negative_index[:10]\n",
    "\n",
    "# positive information\n",
    "                                \n",
    "# print neg_evi[tp]\n",
    "# print pos_evi[tp]\n",
    "\n",
    "pos_info = pos_evi[tp]\n",
    "\n",
    "least_pos_index = np.argwhere(pos_info == np.amin(pos_info))\n",
    "\n",
    "least_pos_index = least_pos_index.flatten().tolist()\n",
    "\n",
    "# print neg_info[least_neg_index]\n",
    "\n",
    "print X_keep_test[tp[least_pos_index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
