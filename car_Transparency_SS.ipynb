{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from classifiers import TransparentLogisticRegression\n",
    "from matplotlib import pylab as pl\n",
    "from scipy.sparse import diags\n",
    "from IPython import display\n",
    "from scale import decision_tree_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# car\n",
    "dataset = \"car.csv\"\n",
    "class_index = 21\n",
    "num_cols = 22\n",
    "classes = ['acc', 'unacc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_cols = [i for i in range(num_cols) if i != class_index]\n",
    "file_path = \"D:\\\\IIT_Master\\\\2016 Spring\\\\CS597\\\\uci\\\\uci\\\\uci-tar\\\\nominal\\\\\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buying=vhigh' 'buying=high' 'buying=med' 'buying=low' 'maint=vhigh'\n",
      " 'maint=high' 'maint=med' 'maint=low' 'doors=2' 'doors=3' 'doors=4'\n",
      " 'doors=5more' 'persons=2' 'persons=4' 'persons=more' 'lug_boot=small'\n",
      " 'lug_boot=med' 'lug_boot=big' 'safety=low' 'safety=med' 'safety=high'\n",
      " 'class\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline()\n",
    "    #print header\n",
    "    #header = np.fromstring(\"a, b\", dtype=np.str_, sep=',')\n",
    "    header = np.array(header.split(','))\n",
    "    feature_names = header[read_cols]\n",
    "    \n",
    "    print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.loadtxt(file_path, dtype=float, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=read_cols)\n",
    "y = np.loadtxt(file_path, dtype=int, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=(class_index,), converters={class_index: lambda x: classes.index(x)})\n",
    "\n",
    "X_train_, X_keep_test, y_train_, y_test_ = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X = scale(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine binary features\n",
    "num_features = X.shape[1]\n",
    "non_binary = []\n",
    "binary = []\n",
    "for i in range(num_features):\n",
    "    if len(np.unique(X[:,i])) != 2:\n",
    "        non_binary.append(i)\n",
    "    else:\n",
    "        binary.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling the train instances\n",
    "\n",
    "\n",
    "X_n = X.copy()\n",
    "\n",
    "if len(non_binary) > 0:\n",
    "    X_n[:,non_binary]=scale(X[:,non_binary])\n",
    "    \n",
    "\n",
    "# for binary features, replace zeros with -1, assuming the other values are 1; a more correct way would check if this was true.\n",
    "if len(binary) > 0:\n",
    "    X_b = X_n[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_n[:,binary] = X_b\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_n, y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransparentLogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "               fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "               multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "               random_state=None, solver='liblinear', tol=0.0001,\n",
       "               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = TransparentLogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prediction = clf.predict(X_test)\n",
    "neg_evi, pos_evi = clf. predict_evidences(X_test)\n",
    "y_prediction_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"unacc\" -- Probability\n",
    "\n",
    "Most_positive = np.argmax(y_prediction_proba[:,1])\n",
    "\n",
    "print X_keep_test[Most_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.\n",
      "  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"acc\" -- Probability\n",
    "\n",
    "Most_negative = np.argmax(y_prediction_proba[:,0])\n",
    "\n",
    "print X_keep_test[Most_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"unacc\" -- Evidence \n",
    "\n",
    "positive_evi_index = np.argmax(pos_evi)\n",
    "\n",
    "print X_keep_test[positive_evi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.\n",
      "  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"acc\" -- Evidence\n",
    "\n",
    "negative_evi_index = np.argmax(abs(neg_evi))\n",
    "\n",
    "# print neg_evi[]\n",
    "\n",
    "print X_keep_test[negative_evi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# unc_1 Top 1 uncertain instances\n",
    "\n",
    "uncertains = np.min(y_prediction_proba, axis=1)\n",
    "\n",
    "uis = np.argsort(uncertains)[::-1]\n",
    "\n",
    "top_10_uis = uis[:10]\n",
    "\n",
    "print X_keep_test[uis[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.\n",
      "  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# unc_ce from Top 10 uncertain instances\n",
    "# print top_10_uis\n",
    "\n",
    "# min the evidence, then argmax to find the most conflicted instances among top 10 uncertain instances\n",
    "\n",
    "min_evidence_top_10 = np.min([abs(neg_evi[top_10_uis]),abs(pos_evi[top_10_uis])], axis=0 )\n",
    "\n",
    "index_ce = np.argmax(min_evidence_top_10)\n",
    "\n",
    "# print min_evidence_top_10\n",
    "# print index_ce\n",
    "# print top_10_uis[index_ce]\n",
    "\n",
    "print X_keep_test[top_10_uis[index_ce]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "# unc_ie from Top 10 uncertain instances \n",
    "\n",
    "# max the nag/pos evidence, then argmin to find least conflicted instances among top 10 uncertain instances\n",
    "\n",
    "max_evidence_top_10 = np.max([abs(neg_evi[top_10_uis]),abs(pos_evi[top_10_uis])], axis=0 )\n",
    "\n",
    "index_ie = np.argmin(min_evidence_top_10)\n",
    "\n",
    "# print min_evidence_top_10\n",
    "# print index_ie\n",
    "# print top_10_uis[index_ie]\n",
    "\n",
    "print X_keep_test[top_10_uis[index_ie]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "   1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Least negative among Top 10 possitive \n",
    "\n",
    "top_positive_index = np.argsort(pos_evi)[::-1]\n",
    "\n",
    "# print neg_evi[top_possitive_index]\n",
    "\n",
    "tp = top_positive_index[:10]\n",
    "\n",
    "# Negative information\n",
    "\n",
    "# print pos_evi[tp]\n",
    "# print neg_evi[tp]\n",
    "\n",
    "neg_info = neg_evi[tp]\n",
    "\n",
    "least_neg_index = np.argwhere(neg_info == np.amax(neg_info))\n",
    "\n",
    "least_neg_index = least_neg_index.flatten().tolist()\n",
    "\n",
    "# print neg_info[least_neg_index]\n",
    "\n",
    "print X_keep_test[tp[least_neg_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.\n",
      "   0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Least positive among Top 10 negative instances\n",
    "\n",
    "top_negative_index = np.argsort(abs(neg_evi))[::-1]\n",
    "tp = top_negative_index[:10]\n",
    "\n",
    "# positive information\n",
    "                                \n",
    "# print neg_evi[tp]\n",
    "# print pos_evi[tp]\n",
    "\n",
    "pos_info = pos_evi[tp]\n",
    "\n",
    "least_pos_index = np.argwhere(pos_info == np.amin(pos_info))\n",
    "\n",
    "least_pos_index = least_pos_index.flatten().tolist()\n",
    "\n",
    "# print neg_info[least_neg_index]\n",
    "\n",
    "print X_keep_test[tp[least_pos_index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
