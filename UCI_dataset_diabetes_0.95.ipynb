{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit\n",
    "from classifiers import TransparentLogisticRegression\n",
    "from matplotlib import pylab as pl\n",
    "from scipy.sparse import diags\n",
    "from IPython import display\n",
    "from scale import decision_tree_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diabetes  http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes\n",
    "# ['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age']\n",
    "# preg: the # of pregnant \n",
    "# plas: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "# pres: Diastolic blood pressure\n",
    "# skin: Triceps skin fold thickness\n",
    "# insu: 2-Hour serum insulin\n",
    "# mass: Body mass index\n",
    "# pedi: Diabetes pedigree function \n",
    "# Age \n",
    "\n",
    "dataset = \"diabetes.csv\"\n",
    "class_index = 8\n",
    "num_cols = 9\n",
    "classes= ['tested_negative', 'tested_positive']\n",
    "read_cols = [i for i in range(num_cols) if i != class_index]\n",
    "file_path = \"D:\\\\IIT_Master\\\\2016 Spring\\\\CS597\\\\uci\\\\uci\\\\uci-tar\\\\nominal\\\\\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age' 'class\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    header = f.readline()\n",
    "    #print header\n",
    "    #header = np.fromstring(\"a, b\", dtype=np.str_, sep=',')\n",
    "    header = np.array(header.split(','))\n",
    "    feature_names = header[read_cols]\n",
    "    \n",
    "    print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (768L, 8L)\n",
      "730\n"
     ]
    }
   ],
   "source": [
    "# Loading the data and splitting the train, test\n",
    "\n",
    "X = np.loadtxt(file_path, dtype=float, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=read_cols)\n",
    "y = np.loadtxt(file_path, dtype=int, delimiter=\",\", skiprows=1, \\\n",
    "                   usecols=(class_index,), converters={class_index: lambda x: classes.index(x)})\n",
    "\n",
    "num_inst, num_feat = np.shape(X)\n",
    "print \"The shape of X:\",np.shape(X)\n",
    "ss = ShuffleSplit(num_inst, n_iter=1, test_size=0.95, random_state=40)\n",
    "\n",
    "for i, j in ss:\n",
    "    train_index = i \n",
    "    test_index = j\n",
    "    \n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine binary features\n",
    "num_features = X.shape[1]\n",
    "non_binary = []\n",
    "binary = []\n",
    "for i in range(num_features):\n",
    "    if len(np.unique(X[:,i])) != 2:\n",
    "        non_binary.append(i)\n",
    "    else:\n",
    "        binary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Scale for non_binary features -- Train\n",
      "IG Scale for non_binary features -- Test\n",
      "['preg' 'plas' 'pres' 'skin' 'insu' 'mass' 'pedi' 'age']\n"
     ]
    }
   ],
   "source": [
    "# Original features\n",
    "X_original = np.copy(X)\n",
    "\n",
    "X_train_ori = X_original[train_index]\n",
    "X_test_ori = X_original[test_index]\n",
    "\n",
    "# Standard scale non binary features\n",
    "\n",
    "X_ss = np.copy(X)\n",
    "# X_ss = scale(X)\n",
    "\n",
    "if len(non_binary) > 0:\n",
    "    X_ss[:,non_binary]=scale(X[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_ss[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_ss[:,binary] = X_b\n",
    "    \n",
    "X_train_ss = X_ss[train_index]\n",
    "X_test_ss = X_ss[test_index]\n",
    "\n",
    "# Information gain scaling non binary features\n",
    "\n",
    "X_ig = np.copy(X_original)\n",
    "scale_ = decision_tree_scale()\n",
    "\n",
    "X_train_ig = X_ig[train_index]\n",
    "X_test_ig = X_ig[test_index]\n",
    "\n",
    "if len(non_binary) > 0: \n",
    "    print \"IG Scale for non_binary features -- Train\"\n",
    "    X_train_ig[:,non_binary]=scale_.fit_transform(X_train_ig[:,non_binary], y_train)\n",
    "\n",
    "if len(binary) > 0: \n",
    "    print \"binary features exist\"\n",
    "    X_b = X_train_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_train_ig[:,binary] = X_b\n",
    "    \n",
    "if len(non_binary) > 0:\n",
    "    \n",
    "    print \"IG Scale for non_binary features -- Test\"\n",
    "    X_test_ig[:,non_binary]=scale_.transform(X_test_ig[:,non_binary])\n",
    "    \n",
    "if len(binary) > 0:\n",
    "    \n",
    "    print \"binary features exist\"\n",
    "    print binary\n",
    "    X_b = X_test_ig[:,binary]\n",
    "    X_b[X_b == 0] = -1\n",
    "    X_test_ig[:,binary] = X_b\n",
    "\n",
    "print header[non_binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of each features:\n",
      "[   3.84505208  120.89453125   69.10546875   20.53645833   79.79947917\n",
      "   31.99257812    0.4718763    33.24088542]\n",
      "The best splitting of each features\n",
      "[   6.5    145.     100.      36.5    426.5     25.45     0.689   32.5  ]\n"
     ]
    }
   ],
   "source": [
    "print \"The mean of each features:\"\n",
    "print np.mean(X, axis=0)\n",
    "print \"The best splitting of each features\"\n",
    "print scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_ori = TransparentLogisticRegression()\n",
    "clf_ss = TransparentLogisticRegression()\n",
    "clf_ig = TransparentLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransparentLogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "               fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "               multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "               random_state=None, solver='liblinear', tol=0.0001,\n",
       "               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit train instances for each classifier\n",
    "\n",
    "clf_ori.fit(X_train_ori, y_train)\n",
    "clf_ss.fit(X_train_ss, y_train)\n",
    "clf_ig.fit(X_train_ig, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04930588  0.02430812 -0.01881217  0.01303152 -0.00316046 -0.0452861\n",
      "   0.82635034  0.00118166]]\n",
      "[[ 0.20000531  0.98910626  0.00593138  0.02499525 -0.31058147  0.28730722\n",
      "   0.68253657  0.33581909]]\n",
      "[[ 0.29559366  0.98362216  0.10191207 -0.09511427 -0.34285464  0.40341875\n",
      "   0.71489413  0.31287842]]\n",
      "\n",
      "[-1.07857429]\n",
      "[-0.57192937]\n",
      "[-0.00846264]\n"
     ]
    }
   ],
   "source": [
    "# print the weights for each classifiers\n",
    "\n",
    "print clf_ori.coef_\n",
    "print clf_ss.coef_\n",
    "print clf_ig.coef_\n",
    "print \"\"\n",
    "\n",
    "print clf_ori.intercept_ \n",
    "print clf_ss.intercept_ \n",
    "print clf_ig.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680821917808\n",
      "0.756164383562\n",
      "0.754794520548\n"
     ]
    }
   ],
   "source": [
    "# Predict test instances for each classifier\n",
    "\n",
    "y_predict_ori = clf_ori.predict(X_test_ori)\n",
    "y_pred_prob_ori = clf_ori.predict_proba(X_test_ori)\n",
    "neg_evi_ori, pos_evi_ori = clf_ori.predict_evidences(X_test_ori)\n",
    "\n",
    "y_predict_ss = clf_ss.predict(X_test_ss)\n",
    "y_pred_prob_ss = clf_ss.predict_proba(X_test_ss)\n",
    "neg_evi_ss, pos_evi_ss = clf_ss.predict_evidences(X_test_ss)\n",
    "\n",
    "y_predict_ig = clf_ig.predict(X_test_ig)\n",
    "y_pred_prob_ig = clf_ig.predict_proba(X_test_ig)\n",
    "neg_evi_ig, pos_evi_ig = clf_ig.predict_evidences(X_test_ig)\n",
    "\n",
    "print accuracy_score(y_test,y_predict_ori)\n",
    "print accuracy_score(y_test,y_predict_ss)\n",
    "print accuracy_score(y_test,y_predict_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(tested_negative) instances based on probability\n",
      "Index of test:  616\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  5.      0.     80.     32.      0.     41.      0.346  37.   ]\n",
      "[ 0.3429808  -3.78365371  0.56322275  0.71908574 -0.69289057  1.14321519\n",
      " -0.38016137  0.31985461]\n",
      "[-0.38746831 -4.0085737  -0.6325804  -0.18122696 -1.14222354  1.60215316\n",
      " -0.8870892   0.41045451]\n",
      "\n",
      "Standard scaling: Most negative(tested_negative) instances based on probability\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.42071715 -4.0085737  -1.64470903 -0.66449885 -1.14222354 -0.07727427\n",
      " -1.41985998 -0.95772719]\n",
      "\n",
      "Information gain scaling: Most negative(tested_negative) instances based on probability\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.42071715 -4.0085737  -1.64470903 -0.66449885 -1.14222354 -0.07727427\n",
      " -1.41985998 -0.95772719]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"tested_negative\" -- Probability\n",
    "\n",
    "Most_negative_1 = np.argmax(y_pred_prob_ori[:,0])\n",
    "print \"Original: Most negative(tested_negative) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_1]\n",
    "print X_test_ss[Most_negative_1]\n",
    "print X_test_ig[Most_negative_1]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_2 = np.argmax(y_pred_prob_ss[:,0])\n",
    "print \"Standard scaling: Most negative(tested_negative) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_2]\n",
    "print X_test_ss[Most_negative_2]\n",
    "print X_test_ig[Most_negative_2]\n",
    "print \"\"\n",
    "\n",
    "Most_negative_3 = np.argmax(y_pred_prob_ig[:,0])\n",
    "print \"Information gain scaling: Most negative(tested_negative) instances based on probability\"\n",
    "print \"Index of test: \",Most_negative_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_negative_3]\n",
    "print X_test_ss[Most_negative_3]\n",
    "print X_test_ig[Most_negative_3]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(tested_positive) instances based on probability\n",
      "Index of test:  497\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   2.     197.      70.      99.       0.      34.7      0.575   62.   ]\n",
      "[-0.54791859  2.38188392  0.04624525  4.92186584 -0.69289057  0.34362394\n",
      "  0.31144581  2.44704844]\n",
      "[-1.16240494  1.43755747 -0.94887059  2.51704109 -1.14222354  0.95304931\n",
      " -0.29483431  2.69075736]\n",
      "\n",
      "Standard scaling: Most positive(tested_positive) instances based on probability\n",
      "Index of test:  425\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   0.    180.     78.     63.     14.     59.4     2.42   25.  ]\n",
      "[-1.14185152  1.84983245  0.45982725  2.66365564 -0.57133003  3.4785293\n",
      "  5.88356477 -0.70119842]\n",
      "[-1.67902936  0.96758676 -0.69583844  1.06722542 -1.10472968  3.49794855\n",
      "  4.47682627 -0.68409085]\n",
      "\n",
      "Information gain scaling: Most positive(tested_positive) instances based on probability\n",
      "Index of test:  425\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   0.    180.     78.     63.     14.     59.4     2.42   25.  ]\n",
      "[-1.14185152  1.84983245  0.45982725  2.66365564 -0.57133003  3.4785293\n",
      "  5.88356477 -0.70119842]\n",
      "[-1.67902936  0.96758676 -0.69583844  1.06722542 -1.10472968  3.49794855\n",
      "  4.47682627 -0.68409085]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"tested_positive\" -- Probability\n",
    "\n",
    "Most_positive_1 = np.argmax(y_pred_prob_ori[:,1])\n",
    "\n",
    "\n",
    "print \"Original: Most positive(tested_positive) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_1\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_1]\n",
    "print X_test_ss[Most_positive_1]\n",
    "print X_test_ig[Most_positive_1]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_2 = np.argmax(y_pred_prob_ss[:,1])\n",
    "print \"Standard scaling: Most positive(tested_positive) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_2\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_2]\n",
    "print X_test_ss[Most_positive_2]\n",
    "print X_test_ig[Most_positive_2]\n",
    "print \"\"\n",
    "\n",
    "Most_positive_3 = np.argmax(y_pred_prob_ig[:,1])\n",
    "print \"Information gain scaling: Most positive(tested_positive) instances based on probability\"\n",
    "print \"Index of test: \",Most_positive_3\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[Most_positive_3]\n",
    "print X_test_ss[Most_positive_3]\n",
    "print X_test_ig[Most_positive_3]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most negative(tested_negative) instances based on evidence\n",
      "Index of test:  660\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  0.00000000e+00   1.65000000e+02   9.00000000e+01   3.30000000e+01\n",
      "   6.80000000e+02   5.23000000e+01   4.27000000e-01   2.30000000e+01]\n",
      "[-1.14185152  1.38037527  1.08020025  0.7818138   5.21147866  2.57740266\n",
      " -0.13553176 -0.87137393]\n",
      "[-1.67902936  0.55290672 -0.3162902  -0.1409543   0.67890661  2.76641881\n",
      " -0.67760167 -0.86651508]\n",
      "\n",
      "Standard scaling: Most negative(tested_negative) instances based on evidence\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.42071715 -4.0085737  -1.64470903 -0.66449885 -1.14222354 -0.07727427\n",
      " -1.41985998 -0.95772719]\n",
      "\n",
      "Information gain scaling: Most negative(tested_negative) instances based on evidence\n",
      "Index of test:  238\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[  1.     0.    48.    20.     0.    24.7    0.14  22.  ]\n",
      "[-0.84488505 -3.78365371 -1.09110524 -0.03365099 -0.69289057 -0.92556851\n",
      " -1.00230582 -0.95646168]\n",
      "[-1.42071715 -4.0085737  -1.64470903 -0.66449885 -1.14222354 -0.07727427\n",
      " -1.41985998 -0.95772719]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most negative, \"tested_negative\" -- Evidence\n",
    "\n",
    "negative_evi_index_ori = np.argmax(abs(neg_evi_ori))\n",
    "print \"Original: Most negative(tested_negative) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ori]\n",
    "print X_test_ss[negative_evi_index_ori]\n",
    "print X_test_ig[negative_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ss = np.argmax(abs(neg_evi_ss))\n",
    "print \"Standard scaling: Most negative(tested_negative) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ss]\n",
    "print X_test_ss[negative_evi_index_ss]\n",
    "print X_test_ig[negative_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "negative_evi_index_ig = np.argmax(abs(neg_evi_ig))\n",
    "print \"Information gain scaling: Most negative(tested_negative) instances based on evidence\"\n",
    "print \"Index of test: \",negative_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[negative_evi_index_ig]\n",
    "print X_test_ss[negative_evi_index_ig]\n",
    "print X_test_ig[negative_evi_index_ig]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Most positive(tested_positive) instances based on evidence\n",
      "Index of test:  431\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   4.     197.      70.      39.     744.      36.7      2.329   31.   ]\n",
      "[ 0.04601433  2.38188392  0.04624525  1.15818217  5.76718399  0.59746243\n",
      "  5.60873397 -0.19067191]\n",
      "[-0.64578052  1.43755747 -0.94887059  0.10068164  0.85030709  1.15911403\n",
      "  4.24147607 -0.13681817]\n",
      "\n",
      "Standard scaling: Most positive(tested_positive) instances based on evidence\n",
      "Index of test:  425\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   0.    180.     78.     63.     14.     59.4     2.42   25.  ]\n",
      "[-1.14185152  1.84983245  0.45982725  2.66365564 -0.57133003  3.4785293\n",
      "  5.88356477 -0.70119842]\n",
      "[-1.67902936  0.96758676 -0.69583844  1.06722542 -1.10472968  3.49794855\n",
      "  4.47682627 -0.68409085]\n",
      "\n",
      "Information gain scaling: Most positive(tested_positive) instances based on evidence\n",
      "Index of test:  425\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   0.    180.     78.     63.     14.     59.4     2.42   25.  ]\n",
      "[-1.14185152  1.84983245  0.45982725  2.66365564 -0.57133003  3.4785293\n",
      "  5.88356477 -0.70119842]\n",
      "[-1.67902936  0.96758676 -0.69583844  1.06722542 -1.10472968  3.49794855\n",
      "  4.47682627 -0.68409085]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most positive, \"tested_positive\" -- Evidence \n",
    "\n",
    "positive_evi_index_ori = np.argmax(pos_evi_ori)\n",
    "print \"Original: Most positive(tested_positive) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ori\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ori]\n",
    "print X_test_ss[positive_evi_index_ori]\n",
    "print X_test_ig[positive_evi_index_ori]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ss = np.argmax(pos_evi_ss)\n",
    "print \"Standard scaling: Most positive(tested_positive) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ss\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ss]\n",
    "print X_test_ss[positive_evi_index_ss]\n",
    "print X_test_ig[positive_evi_index_ss]\n",
    "print \"\"\n",
    "\n",
    "positive_evi_index_ig = np.argmax(pos_evi_ig)\n",
    "print \"Information gain scaling: Most positive(tested_positive) instances based on evidence\"\n",
    "print \"Index of test: \",positive_evi_index_ig\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[positive_evi_index_ig]\n",
    "print X_test_ss[positive_evi_index_ig]\n",
    "print X_test_ig[positive_evi_index_ig]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most uncertain instance based on probability\n",
      "Index of test:  710\n",
      "Actual label 0\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   0.     147.      85.      54.       0.      42.8      0.375   24.   ]\n",
      "[-1.14185152  0.81702665  0.8217115   2.09910309 -0.69289057  1.37166983\n",
      " -0.29257793 -0.78628618]\n",
      "[-1.67902936  0.05529067 -0.4744353   0.70477151 -1.14222354  1.78761141\n",
      " -0.81208749 -0.77530297]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  508\n",
      "Actual label 0\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   0.     137.      84.      27.       0.      27.3      0.231   59.   ]\n",
      "[-1.14185152  0.5040552   0.77001375  0.40544544 -0.69289057 -0.59557847\n",
      " -0.72747502  2.19178518]\n",
      "[-1.67902936 -0.22116269 -0.50606432 -0.38259025 -1.14222354  0.19060986\n",
      " -1.18450978  2.41712101]\n",
      "\n",
      "standard scaling: the most uncertain instance based on probability\n",
      "Index of test:  326\n",
      "Actual label 1\n",
      "The features are (Original, standard scaling, information gain scaling)\n",
      "[   3.     169.      74.      19.     125.      29.9      0.268   31.   ]\n",
      "[-0.25095213  1.50556385  0.25303625 -0.09637905  0.39247142 -0.26558844\n",
      " -0.61573063 -0.19067191]\n",
      "[-0.90409273  0.66348806 -0.82235451 -0.70477151 -0.80745697  0.45849399\n",
      " -1.08881794 -0.13681817]\n",
      "\n",
      "The splitting point:  [   6.5    145.     100.      36.5    426.5     25.45     0.689   32.5  ]\n"
     ]
    }
   ],
   "source": [
    "# unc_1 Top 1 uncertain instances\n",
    "\n",
    "uncertains_ori = np.min(y_pred_prob_ori, axis=1)\n",
    "uis_ori = np.argsort(uncertains_ori)[::-1]\n",
    "top10_uis_ori = uis_ori[:10]\n",
    "print \"Original: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ori[0]\n",
    "print \"Actual label\", y_test[uis_ori[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ori[0]]\n",
    "print X_test_ss[uis_ori[0]]\n",
    "print X_test_ig[uis_ori[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ss = np.min(y_pred_prob_ss, axis=1)\n",
    "uis_ss = np.argsort(uncertains_ss)[::-1]\n",
    "top10_uis_ss = uis_ss[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ss[0]\n",
    "print \"Actual label\", y_test[uis_ss[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ss[0]]\n",
    "print X_test_ss[uis_ss[0]]\n",
    "print X_test_ig[uis_ss[0]]\n",
    "print \"\"\n",
    "\n",
    "uncertains_ig = np.min(y_pred_prob_ig, axis=1)\n",
    "uis_ig = np.argsort(uncertains_ig)[::-1]\n",
    "top10_uis_ig = uis_ig[:10]\n",
    "print \"standard scaling: the most uncertain instance based on probability\"\n",
    "print \"Index of test: \",uis_ig[0]\n",
    "print \"Actual label\", y_test[uis_ig[0]]\n",
    "print \"The features are (Original, standard scaling, information gain scaling)\"\n",
    "print X_test_ori[uis_ig[0]]\n",
    "print X_test_ss[uis_ig[0]]\n",
    "print X_test_ig[uis_ig[0]]\n",
    "print \"\"\n",
    "\n",
    "print \"The splitting point: \", scale_.mns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[710 506 592 173 445 361 108 170 564 589]\n",
      "[508 680  46 218 316 626 415  29 670 673]\n",
      "[326 597 299 400 662 186 344 111 445  11]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 uncertain instances for each classifier\n",
    "\n",
    "print top10_uis_ori\n",
    "print top10_uis_ss\n",
    "print top10_uis_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  592\n",
      "Actual label 0\n",
      "[   6.     154.      78.      41.     140.      46.1      0.571   27.   ]\n",
      "[ 0.63994726  1.03610667  0.45982725  1.28363829  0.52271486  1.79050334\n",
      "  0.29936533 -0.53102292]\n",
      "[-0.1291561   0.24880802 -0.69583844  0.18122696 -0.76728498  2.12761819\n",
      " -0.30517938 -0.50166663]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  218\n",
      "Actual label 1\n",
      "[  5.     85.     74.     22.      0.     29.      1.224  32.   ]\n",
      "[ 0.3429808  -1.12339636  0.25303625  0.09180513 -0.69289057 -0.37981576\n",
      "  2.27150283 -0.10558415]\n",
      "[-0.38746831 -1.65872015 -0.82235451 -0.58395353 -1.14222354  0.36576487\n",
      "  1.38365226 -0.04560606]\n",
      "Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  11\n",
      "Actual label 0\n",
      "[  13.     106.      70.       0.       0.      34.2      0.251   52.   ]\n",
      "[ 2.7187125  -0.46615631  0.04624525 -1.28821221 -0.69289057  0.28016432\n",
      " -0.66707265  1.59617091]\n",
      "[ 1.67902936 -1.0781681  -0.94887059 -1.469952   -1.14222354  0.90153313\n",
      " -1.13278446  1.77863622]\n"
     ]
    }
   ],
   "source": [
    "# unc_ce from Top 10 uncertain instances\n",
    "\n",
    "min_evidence_top10_ori = np.min([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ce_ori = np.argmax(min_evidence_top10_ori)\n",
    "print \"Original: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ce_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ce_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ce_ori]]\n",
    "\n",
    "min_evidence_top10_ss = np.min([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ce_ss = np.argmax(min_evidence_top10_ss)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ce_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ce_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ce_ss]]\n",
    "\n",
    "min_evidence_top10_ig = np.min([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ce_ig = np.argmax(min_evidence_top10_ig)\n",
    "print \"Standard scaling: the most conflicting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ce_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ce_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ce_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  108\n",
      "Actual label 0\n",
      "[   3.    111.     58.     31.     44.     29.5     0.43   22.  ]\n",
      "[-0.25095213 -0.30967058 -0.57412775  0.65635768 -0.31084315 -0.31635613\n",
      " -0.1264714  -0.95646168]\n",
      "[-0.90409273 -0.93994142 -1.32841883 -0.22149962 -1.02438571  0.41728105\n",
      " -0.66984287 -0.95772719]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  415\n",
      "Actual label 0\n",
      "[   4.     120.      68.       0.       0.      29.6      0.709   34.   ]\n",
      "[ 0.04601433 -0.02799627 -0.05715025 -1.28821221 -0.69289057 -0.30366421\n",
      "  0.71614171  0.06459135]\n",
      "[-0.64578052 -0.6911334  -1.01212863 -1.469952   -1.14222354  0.42758429\n",
      "  0.05172532  0.13681817]\n",
      "Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\n",
      "Index of test:  662\n",
      "Actual label 0\n",
      "[   1.     153.      82.      42.     485.      40.6      0.687   23.   ]\n",
      "[-0.84488505  1.00480952  0.66661825  1.34636635  3.51831395  1.09244749\n",
      "  0.6496991  -0.87137393]\n",
      "[-1.42071715  0.22116269 -0.56932236  0.22149962  0.15667076  1.56094022\n",
      " -0.00517253 -0.86651508]\n"
     ]
    }
   ],
   "source": [
    "# unc_ie from Top 10 uncertain instances \n",
    "\n",
    "max_evidence_top10_ori = np.max([abs(neg_evi_ori[top10_uis_ori]),abs(pos_evi_ori[top10_uis_ori])], axis=0)\n",
    "index_ie_ori = np.argmin(max_evidence_top10_ori)\n",
    "print \"Original: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ori[index_ie_ori]\n",
    "print \"Actual label\", y_test[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ori[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ss[top10_uis_ori[index_ie_ori]]\n",
    "print X_test_ig[top10_uis_ori[index_ie_ori]]\n",
    "\n",
    "max_evidence_top10_ss = np.max([abs(neg_evi_ss[top10_uis_ss]),abs(pos_evi_ss[top10_uis_ss])], axis=0)\n",
    "index_ie_ss = np.argmin(max_evidence_top10_ss)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ss[index_ie_ss]\n",
    "print \"Actual label\", y_test[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ori[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ss[top10_uis_ss[index_ie_ss]]\n",
    "print X_test_ig[top10_uis_ss[index_ie_ss]]\n",
    "\n",
    "max_evidence_top10_ig = np.max([abs(neg_evi_ig[top10_uis_ig]),abs(pos_evi_ig[top10_uis_ig])], axis=0)\n",
    "index_ie_ig = np.argmin(max_evidence_top10_ig)\n",
    "print \"Standard scaling: the most leasting instance among 10 uncertain instances based on evidence\"\n",
    "print \"Index of test: \", top10_uis_ig[index_ie_ig]\n",
    "print \"Actual label\", y_test[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ori[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ss[top10_uis_ig[index_ie_ig]]\n",
    "print X_test_ig[top10_uis_ig[index_ie_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 431\n",
      "Actual label 0\n",
      "[   4.     197.      70.      39.     744.      36.7      2.329   31.   ]\n",
      "[ 0.04601433  2.38188392  0.04624525  1.15818217  5.76718399  0.59746243\n",
      "  5.60873397 -0.19067191]\n",
      "[-0.64578052  1.43755747 -0.94887059  0.10068164  0.85030709  1.15911403\n",
      "  4.24147607 -0.13681817]\n",
      "\n",
      "Index of test: 431\n",
      "Actual label 0\n",
      "[   4.     197.      70.      39.     744.      36.7      2.329   31.   ]\n",
      "[ 0.04601433  2.38188392  0.04624525  1.15818217  5.76718399  0.59746243\n",
      "  5.60873397 -0.19067191]\n",
      "[-0.64578052  1.43755747 -0.94887059  0.10068164  0.85030709  1.15911403\n",
      "  4.24147607 -0.13681817]\n",
      "\n",
      "Index of test: 376\n",
      "Actual label 1\n",
      "[   0.     137.      40.      35.     168.      43.1      2.288   33.   ]\n",
      "[-1.14185152  0.5040552  -1.50468724  0.90726993  0.76583594  1.4097456\n",
      "  5.4849091  -0.0204964 ]\n",
      "[-1.67902936 -0.22116269 -1.89774119 -0.06040899 -0.69229727  1.81852112\n",
      "  4.13543917  0.04560606]\n"
     ]
    }
   ],
   "source": [
    "# Least negative among Top 10 possitive \n",
    "\n",
    "top_positive_index_ori = np.argsort(pos_evi_ori)[::-1]\n",
    "tp_ori = top_positive_index_ori[:10]\n",
    "neg_info_ori = neg_evi_ori[tp_ori]\n",
    "index_least_neg_ori = np.argmin(neg_info_ori)\n",
    "print \"Index of test:\",tp_ori[index_least_neg_ori]\n",
    "print \"Actual label\", y_test[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ori[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ss[tp_ori[index_least_neg_ori]]\n",
    "print X_test_ig[tp_ori[index_least_neg_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ss = np.argsort(pos_evi_ss)[::-1]\n",
    "tp_ss = top_positive_index_ss[:10]\n",
    "neg_info_ss = neg_evi_ss[tp_ss]\n",
    "index_least_neg_ss = np.argmin(neg_info_ss)\n",
    "print \"Index of test:\",tp_ss[index_least_neg_ss]\n",
    "print \"Actual label\", y_test[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ori[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ss[tp_ss[index_least_neg_ss]]\n",
    "print X_test_ig[tp_ss[index_least_neg_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_positive_index_ig = np.argsort(pos_evi_ig)[::-1]\n",
    "tp_ig = top_positive_index_ig[:10]\n",
    "neg_info_ig = neg_evi_ig[tp_ig]\n",
    "index_least_neg_ig = np.argmin(neg_info_ig)\n",
    "print \"Index of test:\",tp_ig[index_least_neg_ig]\n",
    "print \"Actual label\", y_test[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ori[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ss[tp_ig[index_least_neg_ig]]\n",
    "print X_test_ig[tp_ig[index_least_neg_ig]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[431 425   0 497 537 311 310 693 515  53]\n",
      "[425 431 311   0 712 537 376 310 693 471]\n",
      "[425 431 311 712   0 376 537 471 412 695]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 positive based on positive evidence\n",
    "\n",
    "print tp_ori\n",
    "print tp_ss\n",
    "print tp_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of test: 145\n",
      "Actual label 1\n",
      "[   9.     171.     110.      24.     240.      45.4      0.721   54.   ]\n",
      "[ 1.53084665  1.56815814  2.11415525  0.21726125  1.39100445  1.70165987\n",
      "  0.75238313  1.76634642]\n",
      "[ 0.64578052  0.71877873  0.3162902  -0.50340822 -0.49947172  2.05549554\n",
      "  0.08276051  1.96106045]\n",
      "\n",
      "Index of test: 404\n",
      "Actual label 0\n",
      "[  0.     94.      0.      0.      0.      0.      0.256  25.   ]\n",
      "[-1.14185152 -0.84172205 -3.57259724 -1.28821221 -0.69289057 -4.06047387\n",
      " -0.65197205 -0.70119842]\n",
      "[-1.67902936 -1.40991213 -3.16290198 -1.469952   -1.14222354 -2.62217351\n",
      " -1.11985313 -0.68409085]\n",
      "\n",
      "Index of test: 642\n",
      "Actual label 0\n",
      "[  2.     56.     56.     28.     45.     24.2     0.332  22.   ]\n",
      "[-0.54791859 -2.03101358 -0.67752325  0.4681735  -0.30216026 -0.98902814\n",
      " -0.42244303 -0.95646168]\n",
      "[-1.16240494 -2.46043489 -1.39167687 -0.34231759 -1.02170758 -0.12879045\n",
      " -0.92329693 -0.95772719]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Least positive among Top 10 negative instances\n",
    "\n",
    "top_negative_index_ori = np.argsort(abs(neg_evi_ori))[::-1]\n",
    "tn_ori = top_negative_index_ori[:10]\n",
    "pos_info_ori = pos_evi_ori[tp_ori]\n",
    "index_least_pos_ori = np.argmin(pos_info_ori)\n",
    "print \"Index of test:\",tn_ori[index_least_pos_ori]\n",
    "print \"Actual label\", y_test[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ori[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ss[tn_ori[index_least_pos_ori]]\n",
    "print X_test_ig[tn_ori[index_least_pos_ori]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ss = np.argsort(abs(neg_evi_ss))[::-1]\n",
    "tn_ss = top_negative_index_ss[:10]\n",
    "pos_info_ss = pos_evi_ss[tp_ss]\n",
    "index_least_pos_ss = np.argmin(pos_info_ss)\n",
    "print \"Index of test:\",tn_ss[index_least_pos_ss]\n",
    "print \"Actual label\", y_test[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ori[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ss[tn_ss[index_least_pos_ss]]\n",
    "print X_test_ig[tn_ss[index_least_pos_ss]]\n",
    "print \"\"\n",
    "\n",
    "top_negative_index_ig = np.argsort(abs(neg_evi_ig))[::-1]\n",
    "tn_ig = top_negative_index_ig[:10]\n",
    "pos_info_ig = pos_evi_ig[tp_ig]\n",
    "index_least_pos_ig = np.argmin(pos_info_ig)\n",
    "print \"Index of test:\",tn_ig[index_least_pos_ig]\n",
    "print \"Actual label\", y_test[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ori[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ss[tn_ig[index_least_pos_ig]]\n",
    "print X_test_ig[tn_ig[index_least_pos_ig]]\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[660 258 431 118 111 160 544 421 662 145]\n",
      "[238 470 204 616 543  10 461 728 642 404]\n",
      "[238 470 204 543 616 461 728 404  10 642]\n"
     ]
    }
   ],
   "source": [
    "# The indices of top 10 negative based on negative evidence\n",
    "\n",
    "print tn_ori\n",
    "print tn_ss\n",
    "print tn_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
